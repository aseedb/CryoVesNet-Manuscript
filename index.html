<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Amin Khosrozadeh" />
  <meta name="author" content="Raphaela Seeger" />
  <meta name="author" content="Guillaume Witz" />
  <meta name="author" content="Julika Radecke" />
  <meta name="author" content="Jakob B. Sørensen" />
  <meta name="author" content="Benoît Zuber" />
  <meta name="dcterms.date" content="2024-06-18" />
  <meta name="keywords" content="synapse, cryo-electron tomography, synaptic vesicles, deep learning, segmentation, post-processing, automation" />
  <title>CryoVesNet: A Dedicated Framework for Synaptic Vesicle Segmentation in Cryo Electron Tomograms</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  --> ¶ <meta name="dc.format" content="text/html" /> ¶ <meta property="og:type" content="article" /> ¶ <meta name="dc.title" content="CryoVesNet: A Dedicated Framework for Synaptic Vesicle Segmentation in Cryo Electron Tomograms" /> ¶ <meta name="citation_title" content="CryoVesNet: A Dedicated Framework for Synaptic Vesicle Segmentation in Cryo Electron Tomograms" /> ¶ <meta property="og:title" content="CryoVesNet: A Dedicated Framework for Synaptic Vesicle Segmentation in Cryo Electron Tomograms" /> ¶ <meta property="twitter:title" content="CryoVesNet: A Dedicated Framework for Synaptic Vesicle Segmentation in Cryo Electron Tomograms" /> ¶ <meta name="dc.date" content="2024-06-18" /> ¶ <meta name="citation_publication_date" content="2024-06-18" /> ¶ <meta property="article:published_time" content="2024-06-18" /> ¶ <meta name="dc.modified" content="2024-06-18T13:49:47+00:00" /> ¶ <meta property="article:modified_time" content="2024-06-18T13:49:47+00:00" /> ¶ <meta name="dc.language" content="en-US" /> ¶ <meta name="citation_language" content="en-US" /> ¶ <meta name="dc.relation.ispartof" content="Manubot" /> ¶ <meta name="dc.publisher" content="Manubot" /> ¶ <meta name="citation_journal_title" content="Manubot" /> ¶ <meta name="citation_technical_report_institution" content="Manubot" /> ¶ <meta name="citation_author" content="Amin Khosrozadeh" /> ¶ <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" /> ¶ <meta name="citation_author_institution" content="Graduate School for Cellular and Biomedical Sciences, University of Bern" /> ¶ <meta name="citation_author_orcid" content="0000-0001-9480-5915" /> ¶ <meta name="citation_author" content="Raphaela Seeger" /> ¶ <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" /> ¶ <meta name="citation_author_institution" content="Graduate School for Cellular and Biomedical Sciences, University of Bern" /> ¶ <meta name="citation_author_orcid" content="0000-0003-4461-3741" /> ¶ <meta name="citation_author" content="Guillaume Witz" /> ¶ <meta name="citation_author_institution" content="Data Science Lab, University of Bern, Bern, Switzerland" /> ¶ <meta name="citation_author_orcid" content="0000-0003-1562-4265" /> ¶ <meta name="citation_author" content="Julika Radecke" /> ¶ <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" /> ¶ <meta name="citation_author_institution" content="Department of Neuroscience, Faculty of Health and Medical Science, 2200 Copenhagen N, University of Copenhagen, Copenhagen, Denmark" /> ¶ <meta name="citation_author_institution" content="Diamond Light Source Ltd, Didcot, Oxfordshire, United Kingdom" /> ¶ <meta name="citation_author_orcid" content="0000-0002-5815-5537" /> ¶ <meta name="citation_author" content="Jakob B. Sørensen" /> ¶ <meta name="citation_author_institution" content="Department of Neuroscience, University of Copenhagen, Blegdamsvej 3B, 2200 Copenhagen N, Denmark" /> ¶ <meta name="citation_author_orcid" content="0000-0001-5465-3769" /> ¶ <meta name="citation_author" content="Benoît Zuber" /> ¶ <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" /> ¶ <meta name="citation_author_orcid" content="0000-0001-7725-5579" /> ¶ <link rel="canonical" href="https://aseedb.github.io/CryoVesNet-Manuscript/" /> ¶ <meta property="og:url" content="https://aseedb.github.io/CryoVesNet-Manuscript/" /> ¶ <meta property="twitter:url" content="https://aseedb.github.io/CryoVesNet-Manuscript/" /> ¶ <meta name="citation_fulltext_html_url" content="https://aseedb.github.io/CryoVesNet-Manuscript/" /> ¶ <meta name="citation_pdf_url" content="https://aseedb.github.io/CryoVesNet-Manuscript/manuscript.pdf" /> ¶ <link rel="alternate" type="application/pdf" href="https://aseedb.github.io/CryoVesNet-Manuscript/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://aseedb.github.io/CryoVesNet-Manuscript/v/fb227471c7315a33a61bf16fe2393f9df7e7ecf6/" /> ¶ <meta name="manubot_html_url_versioned" content="https://aseedb.github.io/CryoVesNet-Manuscript/v/fb227471c7315a33a61bf16fe2393f9df7e7ecf6/" /> ¶ <meta name="manubot_pdf_url_versioned" content="https://aseedb.github.io/CryoVesNet-Manuscript/v/fb227471c7315a33a61bf16fe2393f9df7e7ecf6/manuscript.pdf" /> ¶ <meta property="og:type" content="article" /> ¶ <meta property="twitter:card" content="summary_large_image" /> ¶ <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" /> ¶ <meta name="theme-color" content="#ad1457" /> ¶ <!-- end Manubot generated metadata -->
  
  <!-- pandoc-eqnos: equation style -->
  <style>
    .eqnos { display: inline-block; position: relative; width: 100%; }
    .eqnos br { display: none; }
    .eqnos-number { position: absolute; right: 0em; top: 50%; line-height: 0; }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">CryoVesNet: A Dedicated Framework for Synaptic Vesicle Segmentation in Cryo Electron Tomograms</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://aseedb.github.io/CryoVesNet-Manuscript/v/fb227471c7315a33a61bf16fe2393f9df7e7ecf6/">permalink</a>)
was automatically generated
from <a href="https://github.com/aseedb/CryoVesNet-Manuscript/tree/fb227471c7315a33a61bf16fe2393f9df7e7ecf6">aseedb/CryoVesNet-Manuscript@fb22747</a>
on June 18, 2024.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Amin Khosrozadeh</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-9480-5915">0000-0001-9480-5915</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland; Graduate School for Cellular and Biomedical Sciences, University of Bern
</small></p></li>
<li><p><strong>Raphaela Seeger</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-4461-3741">0000-0003-4461-3741</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland; Graduate School for Cellular and Biomedical Sciences, University of Bern
</small></p></li>
<li><p><strong>Guillaume Witz</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-1562-4265">0000-0003-1562-4265</a>
<br>
<small>
Data Science Lab, University of Bern, Bern, Switzerland
</small></p></li>
<li><p><strong>Julika Radecke</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-5815-5537">0000-0002-5815-5537</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/julikaradecke">julikaradecke</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland; Department of Neuroscience, Faculty of Health and Medical Science, 2200 Copenhagen N, University of Copenhagen, Copenhagen, Denmark; Diamond Light Source Ltd, Didcot, Oxfordshire, United Kingdom
</small></p></li>
<li><p><strong>Jakob B. Sørensen</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5465-3769">0000-0001-5465-3769</a>
<br>
<small>
Department of Neuroscience, University of Copenhagen, Blegdamsvej 3B, 2200 Copenhagen N, Denmark
</small></p></li>
<li><p><strong>Benoît Zuber</strong>
<sup><a href="#correspondence">✉</a></sup><br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-7725-5579">0000-0001-7725-5579</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland
</small></p></li>
</ul>
<div id="correspondence">
<p>Correspondence to
Benoît Zuber &lt;benoit.zuber@unibe.ch&gt;.</p>
</div>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>Cryo-electron Tomography (Cryo-ET) has the potential to reveal cell structure down to atomic resolution.
Nevertheless, cellular cryo-ET data is often highly complex, and visualization, as well as quantification, of subcellular structures require image segmentation.
Due to a relatively high level of noise and anisotropic resolution in cryo-ET data, automatic segmentation based on classical computer vision approaches usually does not perform satisfactorily.
For this reason, cryo-ET researchers have mostly performed manual segmentation.</p>
<p>Communication between neurons relies on neurotransmitter-filled synaptic vesicle (SV) exocytosis.
Recruitment of SVs to the plasma membrane is an important means of regulating exocytosis and is influenced by interactions between SVs.
Cryo-ET study of the spatial organization of SVs and of their interconnections allows a better understanding of the mechanisms of exocytosis regulation.
Extremely accurate SV segmentation is a prerequisite to obtaining a faithful representation of SVs state of connectivity.
Hundreds to thousands of SVs are present in a typical synapse, and their time-consuming manual segmentation is a bottleneck in this analysis.</p>
<p>Several attempts to automate vesicle segmentation by classical computer vision or machine learning algorithms have not yielded robust results.
We addressed this problem by designing a workflow consisting of a U-Net convolutional segmentation network followed by post-processing steps.
This combination yields highly accurate results.
Furthermore, we provide an interactive tool for accurately segmenting spherical vesicles in a fraction of the time required by available manual segmentation methods.
This tool can be used to segment vesicles that were missed by the fully automatic procedure or to quickly segment a handful of vesicles while bypassing the fully automatic procedure.
Our pipeline can in principle be used to segment any spherical vesicle in any cell type as well as extracellular vesicles.</p>
<h2 id="introduction">Introduction</h2>
<p>The fine architecture of cells can be investigated by cryo-electron tomography (cryo-ET) <span class="citation" data-cites="IpfJPPLG">[<a href="#ref-IpfJPPLG" role="doc-biblioref">1</a>]</span>.
Cellular structures are preserved down to the atomic scale through vitrification and observation of the samples in a fully hydrated state.
When a macromolecule is present in a sufficient number of copies in the cells imaged by cryo-ET, it is possible to obtain its atomic structure in situ using subtomogram averaging <span class="citation" data-cites="2TrAHWcN EGfvt7aR">[<a href="#ref-2TrAHWcN" role="doc-biblioref">2</a>,<a href="#ref-EGfvt7aR" role="doc-biblioref">3</a>]</span>.
Cellular cryo-ET datasets are usually extremely complex, making them difficult to analyze.
This is aggravated by the sensitivity of biological samples to electron radiation, which limits the signal-to-noise ratio in cryo-ET datasets <span class="citation" data-cites="WmTa9taa">[<a href="#ref-WmTa9taa" role="doc-biblioref">4</a>]</span>.
Tomographic reconstructions are generated from a series of images of the sample acquired at different viewing angles.
The geometry of the samples prevents acquisition at certain angles, resulting in anisotropic spatial coverage.
The resolution in the directions close to the axis of the electron beam incident on the untilted sample is strongly reduced.
This effect, commonly referred to as the missing-wedge artifact, further complicates data analysis.
In particular, organelles fully bounded by a membrane appear to have holes at their top and bottom (relative to the electron beam axis) <span class="citation" data-cites="WmTa9taa">[<a href="#ref-WmTa9taa" role="doc-biblioref">4</a>]</span>.</p>
<p>The synapse is a specialized cellular contact at which information is transmitted from a neuron to another, the presynaptic and postsynaptic synapses, respectively.
In most cases, the signal is transmitted by the release of neurotransmitters into the intercellular space.
Neurotransmitters are stored in SVs and are released following the fusion of an SV with the presynaptic plasma membrane.
A synapse contains hundreds of SVs and their mobility and recruitability for neurotransmitter release depends on inter-vesicle interactions through so-called connector structures <span class="citation" data-cites="XQJ3R1HJ kjMcXSJ3 K10hpz3n Lw7FpxSz">[<a href="#ref-XQJ3R1HJ" role="doc-biblioref">5</a>,<a href="#ref-kjMcXSJ3" role="doc-biblioref">6</a>,<a href="#ref-K10hpz3n" role="doc-biblioref">7</a>,<a href="#ref-Lw7FpxSz" role="doc-biblioref">8</a>]</span>.
The characterization of these interactions can be performed automatically with the Pyto software, which implements a hierarchical connectivity approach to segment connectors <span class="citation" data-cites="1HtRUUZQi">[<a href="#ref-1HtRUUZQi" role="doc-biblioref">9</a>]</span>.
For accurate connector segmentation, precise segmentation of SVs is a prerequisite.
To date, SV segmentation has been performed manually, but given the large number of SVs per dataset, it is an extremely time-consuming process.
Typically, one person spends 3 to 8 working days segmenting a single dataset.
Attempts to perform this task automatically based on classical computer vision algorithms have not yielded sufficiently accurate results <span class="citation" data-cites="JWuvfT0Z">[<a href="#ref-JWuvfT0Z" role="doc-biblioref">10</a>]</span>.
To alleviate this situation, we decided to develop an approach based on deep learning.</p>
<p>Convolutional neural networks (CNN) have been successfully employed to segment cryo-ET data <span class="citation" data-cites="GNLHO53d">[<a href="#ref-GNLHO53d" role="doc-biblioref">11</a>]</span>.
Although sufficient for visualization purposes, this approach has not met the requirements to segmenting tethers and connectors in Pyto.
Later on, Imbrosci et al. described accurate SV segmentation of transmission electron microscopy images using CNN, but this approach is limited to 2-dimensional (2D) images of resin-embedded synapses <span class="citation" data-cites="RdPTGoZx">[<a href="#ref-RdPTGoZx" role="doc-biblioref">12</a>]</span>.
In the former study, cryo-ET data are decomposed in individual 2D slices, which are handed as separate inputs to the CNN.
The independent output 2D prediction images are then reassembled in a 3-dimensional (3D) stack <span class="citation" data-cites="GNLHO53d">[<a href="#ref-GNLHO53d" role="doc-biblioref">11</a>]</span>.
As discussed above, membranes oriented approximately parallel to the plane of the 2D tomographic images are not resolved.
In the absence of contextual knowledge of the other 2D images, the CNN fails to segment these regions of the vesicles.
Hence, spherical vesicles appear open, whereas we expect closed spherical objects.
Recently Zhou et al. addressed this issue by implementing a downstream fitting step based on a Gaussian process approach, allowing for the smooth closure of the membranes <span class="citation" data-cites="pMX2OxF7">[<a href="#ref-pMX2OxF7" role="doc-biblioref">13</a>]</span>.
Ideally, 3D networks should be used to segment 3D cryo-ET data.
In this context, several groups have published applications of 3D networks in cryo-ET for other tasks, such as particle picking and classification, in order to perform subtomogram averaging <span class="citation" data-cites="xhywoibB VobzV1Lb NGTzBMdU">[<a href="#ref-xhywoibB" role="doc-biblioref">14</a>,<a href="#ref-VobzV1Lb" role="doc-biblioref">15</a>,<a href="#ref-NGTzBMdU" role="doc-biblioref">16</a>]</span>.
However, these papers have not focused on accurately segmenting membranes in cryo-ET data.</p>
<p>We opted to employ a 3D U-Net CNN to process 3D images as input <span class="citation" data-cites="D7hXMn0y">[<a href="#ref-D7hXMn0y" role="doc-biblioref">17</a>]</span>.
Weigert et al. <span class="citation" data-cites="12G712Zky">[<a href="#ref-12G712Zky" role="doc-biblioref">18</a>]</span> implemented a U-Net for content-aware restoration (CARE) of 3D fluorescence microscopy datasets.
They showed that it can restore information from anisotropic and very noisy datasets.
Such networks have been used in the last couple of years in cryo-ET analysis, mainly to perform denoising and object detection <span class="citation" data-cites="vFGVscEl VobzV1Lb xhywoibB">[<a href="#ref-xhywoibB" role="doc-biblioref">14</a>,<a href="#ref-VobzV1Lb" role="doc-biblioref">15</a>,<a href="#ref-vFGVscEl" role="doc-biblioref">19</a>]</span>.
We implemented a 3D U-Net based on CARE building blocks and trained it with manually segmented datasets.
This method provided good accuracy and was not strongly affected by the missing wedge artifact.
Nevertheless, it was not sufficient for our downstream Pyto analysis.
Hence, we developed a post-processing method, which transforms the segmented objects into spheres and refines their radius and center location.
The workflow includes outlier detection based on the radial profile features of the segmented objects.
Then, these mis-segmented vesicles can be either removed or refined.
This leads to a substantial improvement in accuracy, which is reflected in Pyto performances comparable to those obtained after manual SV segmentation.
We also introduce a semi-automatic method to quickly fix wrongly segmented or missed SVs.</p>
<p>Although our set of procedures was developed with the use case of SV segmentation in mind, it can be used to segment any other types of biological spherical vesicles, such as transport vesicles, secretory vesicles, endocytic vesicles, and extracellular vesicles.
Furthermore, with only small modifications it could be extended to extremely accurate segmentation of other membrane-bound organelles or to the plasma membrane.</p>
<h2 id="results">Results</h2>
<h3 id="overview-of-training-and-workflow">Overview of training and workflow</h3>
<p>In view of the effort required for the manual segmentation of SVs, we decided to develop an automatic segmentation procedure.
Since we had previously manually segmented a number of tomograms with the program IMOD, we could use these segmentations as the ground truth <span class="citation" data-cites="136NHHp17">[<a href="#ref-136NHHp17" role="doc-biblioref">20</a>]</span>.
We trained a U-Net with a set of 9 segmented tomograms of rat synaptosomes (see Materials and Methods).</p>
<p>We sought to further improve segmentation accuracy by feeding the probability mask output by the U-Net to a series of post-processing steps (Figure <a href="#fig:pipeline">1</a>).
Three sets of tomograms were used to assess the performances of the pipeline:</p>
<ol type="1">
<li>Train tomograms : The 9 rat synaptosome tomograms that have been used for U-Net training</li>
<li>Test tomograms: 9 additional rat synaptosome tomograms</li>
<li>Generalization test tomograms: 12 mouse primary neuronal culture tomograms.</li>
</ol>
<p>Each tomogram was split into patches of 32<sup>3</sup> voxels.
These patches were fed in the U-Net, which outputs a probability mask for those patches.
To obtain a complete probability mask, the patches are stitched back together (Figure <a href="#fig:pipeline">1</a>, Figure <a href="#fig:suppl_tom_slice">EV1</a>).
The probability mask was then binarized with a global threshold step.</p>
<div id="fig:pipeline" class="fignos">
<figure>
<img src="images/latest_pipline.png" style="width:20cm" alt="Figure 1: Pipeline of automatic segmentation. a) Tomograms b) Splitting in 3D patches c) Segmentation Network/ trained U-Net d) probability masks e) stitching patches back together f) thresholding h) radial profile i) outlier removal j) Segmented Vesicles" />
<figcaption aria-hidden="true"><span>Figure 1:</span> <strong>Pipeline of automatic segmentation.</strong> a) Tomograms b) Splitting in 3D patches c) Segmentation Network/ trained U-Net d) probability masks e) stitching patches back together f) thresholding h) radial profile i) outlier removal j) Segmented Vesicles</figcaption>
</figure>
</div>
<p>We noticed that some vesicles were not segmented accurately.
Indeed, some vesicles that were in close proximity were misidentified as a single entity.
Separating them necessitated adjusting the detection threshold to a more stringent value. (see “Adaptative local thresholding” section in Materials and Methods).
Additionally, there were instances where the detection captured only a fraction of a vesicle, which required loosening the threshold for a more accurate segmentation.
Yet the assignment of the correct label to each segmented vesicle was essential for the next steps.</p>
<h3 id="sphericalization-and-radial-profile-based-refinement">Sphericalization and radial profile-based refinement</h3>
<p>Although at first glance the segmentation looked good after these steps, we noticed that it was not extremely accurate.
For example, the vesicles were not always centered in the segment or the radius of the segment was inexact.
Very often, the vesicle segment looked shrunk in the z-direction, whereas the actual vesicles were spherical.
This would be highly problematic for automatic connector and tether segmentation.
To address these issues, we represented each vesicle as a sphere.
We determined the center and radius of the sphere as described in the Materials and Methods section.
We then performed a radial averaging of the intensity around the center of the sphere.
And we adjusted iteratively the position and radius of the sphere to match the actual structure in the tomogram (Figure <a href="#fig:radial_profile">2</a>). The radial profile refinement is a pivotal tool as it ensures that the segmented vesicles are a true representation of their form in the tomogram.</p>
<div id="fig:radial_profile" class="fignos">
<figure>
<img src="images/radial_avg_115-139.svg" style="width:15cm" alt="Figure 2: Vesicle radius and position refinment through radial profile and cross-correlation. (A) Initial segmentation of a vesicle. (B) Radial Profile. Blue range is from membrane center to outer white halo center. This is defined as the search range for the optimal radius. (C) second derivative of radial profile, used to define the exact edge of the membrane. (D) Central cross-section in the three-dimensional radial average of the vesicle in its initial position. (E-H) Same as (A-D) after refinement." />
<figcaption aria-hidden="true"><span>Figure 2:</span> <strong>Vesicle radius and position refinment through radial profile and cross-correlation</strong>. (A) Initial segmentation of a vesicle. (B) Radial Profile. Blue range is from membrane center to outer white halo center. This is defined as the search range for the optimal radius. (C) second derivative of radial profile, used to define the exact edge of the membrane. (D) Central cross-section in the three-dimensional radial average of the vesicle in its initial position. (E-H) Same as (A-D) after refinement.</figcaption>
</figure>
</div>
<h3 id="outlier-detection-and-refinement">Outlier detection and refinement</h3>
<p>Despite the improvement brought by the radial profile refinement, some vesicles were still not segmented accurately.
By quantifying several parameters of the segmented vesicles, such as radius, membrane thickness, membrane intensity, lumen intensity, we were able to spot outliers using multivariate statistics (see Materials and Methods).
An example of outlier detection is shown in Figure <a href="#fig:outlier">3</a>.
In this example, three outliers are highlighted.
Outlier 1 (red, top row) corresponds to the mistaken segmentation of a non-vesicular membrane-bound structure.
The high mahalanobis distance of this outlier can be explained by a vesicle radius, membrane thickness, and intensity that are very different from the average of the dataset.
Outlier 2 (green, middle row) is correctly segmented but is flagged for its abnormally high radius.
Indeed, both the membrane thickness and intensity are close to the average of the dataset but the highly increased radius leads to a high mahalanobis distance.
Outlier 3 (blue, bottom row) is initially detected but is misplaced.
Its radius was not divergent from the average but its membrane thickness and intensity were.
We could then refine these outliers or remove them if refinement failed.</p>
<div id="fig:outlier" class="fignos">
<figure>
<img src="images/outlier_intensity_border.png" style="width:15cm" alt="Figure 3: Multidimensional Outlier Detection. The scatter plot (left panel) represents vesicle features in the space defined by membrane intensity, radius, and thickness, with points colored according to the p-value of their Mahalanobis distance, identifying potential outliers. Central panels: outliers are highlighted. Right panels: outliers have been either removed (top and middle row) or fixed by refinement(bottom row). In addition the right panels show the final vesicle segmentation boundaries. Bars, 100 nm." />
<figcaption aria-hidden="true"><span>Figure 3:</span> <strong>Multidimensional Outlier Detection</strong>. The scatter plot (left panel) represents vesicle features in the space defined by membrane intensity, radius, and thickness, with points colored according to the p-value of their Mahalanobis distance, identifying potential outliers. Central panels: outliers are highlighted. Right panels: outliers have been either removed (top and middle row) or fixed by refinement(bottom row). In addition the right panels show the final vesicle segmentation boundaries. Bars, 100 nm.</figcaption>
</figure>
</div>
<h3 id="performance-and-generalization">Performance and generalization</h3>
<p>The performance of all steps was quantitatively assessed by comparing the obtained segmentation with the ground truth using the Dice coefficient metric (see Materials and Methods).
The Dice coefficient of the probability mask was 0.64±0.11 for the train tomograms, 0.75±0.06 for the test tomograms, and 0.69±0.09 for the generalization test tomograms (Table <a href="#tbl:train-tomograms">1</a>, Table <a href="#tbl:test-tomograms">2</a>, Table <a href="#tbl:neuron-tomograms">3</a>, Table <a href="#tbl:dice-statistics">EV1</a>, Table <a href="#tbl:dice-pvalues">EV2</a>, and Figure <a href="#fig:dice-improv">4</a>).
The probability mask was then binarized with a global threshold step, which led to a Dice of 0.78±0.04 and 0.80±0.04 in the train and test datasets, respectively, while it led to a slight decrease dice of 0.66±0.09 in the generalization test dataset.
You do not see instantly that localized thresholding step affect the performance significantly however, it is necessarily to avoid false negative vesicles.
The Radial profile refinement and final outlier removal steps led to a Dice coefficients of 0.86±0.05, 0.83±0.05, and 0.79±0.09, respectively.</p>
<p>In addition to the Dice metric, which is a voxel-wise evaluation, we performed a vesicle-wise evaluation.
Namely, we quantified vesicle diameter deviation, and center residual (Figure <a href="#fig:dice-improv">4</a>, Table <a href="#tbl:train-tomograms">1</a>, Table <a href="#tbl:test-tomograms">2</a>, and Table <a href="#tbl:neuron-tomograms">3</a>).
Results show that our method transfers well across datasets even without fine-tuning which shows robustness and generalization.</p>
<h3 id="train-dataset-metrics">Train Dataset Metrics</h3>
<div id="tbl:train-tomograms" class="tablenos">
<table id="tbl:train-tomograms" style="width:100%;">
<caption><span>Table 1:</span> <strong>Evaluation of the segmentation on the synaptosomal train set</strong>. Mask Dice: Mask Dice coefficient for the predicted mask; Final Label Dice: Dice coefficient after post-processing; δ d: average relative diameter deviation over all correctly detected vesicles; Δ c: center residual error average and standard deviation (nm); Number of Vesicles: number of expected vesicles; TP: True Positive; FN: False Negative; FP: False Positive; F1-score: F1-score based on TP, FN, and FP.
</caption>
<colgroup>
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong><em>Dataset</em></strong></th>
<th style="text-align: center;"><strong><em>Mask Dice</em></strong></th>
<th style="text-align: center;"><strong><em>Final Label Dice</em></strong></th>
<th style="text-align: center;"><strong><em>δ_d</em></strong></th>
<th style="text-align: center;"><strong><em>Δ_c (nm)</em></strong></th>
<th style="text-align: center;"><strong><em>Number of Vesicles</em></strong></th>
<th style="text-align: center;"><strong><em>TP</em></strong></th>
<th style="text-align: center;"><strong><em>FN</em></strong></th>
<th style="text-align: center;"><strong><em>FP</em></strong></th>
<th style="text-align: center;"><strong><em>F1-score</em></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">SC 1</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">2.55±1.91</td>
<td style="text-align: center;">223</td>
<td style="text-align: center;">188</td>
<td style="text-align: center;">35</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">0.874</td>
</tr>
<tr class="even">
<td style="text-align: center;">SC 2</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">2.08±1.06</td>
<td style="text-align: center;">105</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.990</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SC 3</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.77±0.85</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.992</td>
</tr>
<tr class="even">
<td style="text-align: center;">SC 4</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">1.78±0.9</td>
<td style="text-align: center;">144</td>
<td style="text-align: center;">138</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.972</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SC 5</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">1.84±1.01</td>
<td style="text-align: center;">214</td>
<td style="text-align: center;">190</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.934</td>
</tr>
<tr class="even">
<td style="text-align: center;">SC 6</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">1.86±1.03</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">102</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">0.958</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SC 7</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">1.92±0.94</td>
<td style="text-align: center;">184</td>
<td style="text-align: center;">184</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.974</td>
</tr>
<tr class="even">
<td style="text-align: center;">SC 8</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.76±1.12</td>
<td style="text-align: center;">132</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.981</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SC 9</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2.0±1.15</td>
<td style="text-align: center;">135</td>
<td style="text-align: center;">132</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.978</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Average</strong></td>
<td style="text-align: center;"><strong>0.80±0.04</strong></td>
<td style="text-align: center;"><strong>0.88±0.04</strong></td>
<td style="text-align: center;"><strong>0.05±0.01</strong></td>
<td style="text-align: center;"><strong>1.95±1.11</strong></td>
<td style="text-align: center;"><strong>152.11</strong></td>
<td style="text-align: center;"><strong>95.64%</strong></td>
<td style="text-align: center;"><strong>4.36%</strong></td>
<td style="text-align: center;"><strong>3.25%</strong></td>
<td style="text-align: center;"><strong>0.961±0.037</strong></td>
</tr>
</tbody>
</table>
</div>
<h3 id="test-dataset-metrics">Test Dataset Metrics</h3>
<div id="tbl:test-tomograms" class="tablenos">
<table id="tbl:test-tomograms" style="width:100%;">
<caption><span>Table 2:</span> <strong>Evaluation of the segmentation on the synaptosomal test set</strong> (same sample type as the train set). For the meaning of the columns, see Table <a href="#tbl:train-tomograms">1</a>.
</caption>
<colgroup>
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong><em>Dataset</em></strong></th>
<th style="text-align: center;"><strong><em>Mask Dice</em></strong></th>
<th style="text-align: center;"><strong><em>Final Label Dice</em></strong></th>
<th style="text-align: center;"><strong><em>δ_d</em></strong></th>
<th style="text-align: center;"><strong><em>Δ_c (nm)</em></strong></th>
<th style="text-align: center;"><strong><em>Number of Vesicles</em></strong></th>
<th style="text-align: center;"><strong><em>TP</em></strong></th>
<th style="text-align: center;"><strong><em>FN</em></strong></th>
<th style="text-align: center;"><strong><em>FP</em></strong></th>
<th style="text-align: center;"><strong><em>F1-score</em></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">ST 1</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">2.61±1.51</td>
<td style="text-align: center;">699</td>
<td style="text-align: center;">683</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.987</td>
</tr>
<tr class="even">
<td style="text-align: center;">ST 2</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">2.31±1.72</td>
<td style="text-align: center;">122</td>
<td style="text-align: center;">117</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.975</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ST 3</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.10</td>
<td style="text-align: center;">3.6±2.28</td>
<td style="text-align: center;">434</td>
<td style="text-align: center;">380</td>
<td style="text-align: center;">54</td>
<td style="text-align: center;">22</td>
<td style="text-align: center;">0.909</td>
</tr>
<tr class="even">
<td style="text-align: center;">ST 5</td>
<td style="text-align: center;">0.79</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">2.22±1.27</td>
<td style="text-align: center;">535</td>
<td style="text-align: center;">514</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">0.966</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ST 6</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">1.98±0.99</td>
<td style="text-align: center;">373</td>
<td style="text-align: center;">355</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">0.945</td>
</tr>
<tr class="even">
<td style="text-align: center;">ST 7</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.82</td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">2.26±1.23</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">107</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">0.955</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ST 8</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">2.14±1.05</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.995</td>
</tr>
<tr class="even">
<td style="text-align: center;">SC 10</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">1.92±1.22</td>
<td style="text-align: center;">129</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.973</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ST 10</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">1.89±1.0</td>
<td style="text-align: center;">76</td>
<td style="text-align: center;">75</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.962</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Average</strong></td>
<td style="text-align: center;"><strong>0.78±0.03</strong></td>
<td style="text-align: center;"><strong>0.85±0.05</strong></td>
<td style="text-align: center;"><strong>0.07±0.03</strong></td>
<td style="text-align: center;"><strong>2.33±1.36</strong></td>
<td style="text-align: center;"><strong>286.44</strong></td>
<td style="text-align: center;"><strong>96.31%</strong></td>
<td style="text-align: center;"><strong>3.69%</strong></td>
<td style="text-align: center;"><strong>3.63%</strong></td>
<td style="text-align: center;"><strong>0.963±0.025</strong></td>
</tr>
</tbody>
</table>
</div>
<h3 id="out-of-distribution-dataset">Out-of-distribution dataset</h3>
<div id="tbl:neuron-tomograms" class="tablenos">
<table id="tbl:neuron-tomograms" style="width:100%;">
<caption><span>Table 3:</span> <strong>Evaluation of the segmentation on the neuronal generalization test set</strong> (different sample type as the train set). For the meaning of the columns, see Table <a href="#tbl:train-tomograms">1</a>.
</caption>
<colgroup>
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><strong><em>Dataset</em></strong></th>
<th style="text-align: center;"><strong><em>Mask Dice</em></strong></th>
<th style="text-align: center;"><strong><em>Final Label Dice</em></strong></th>
<th style="text-align: center;"><strong><em>δ_d</em></strong></th>
<th style="text-align: center;"><strong><em>Δ_c (nm)</em></strong></th>
<th style="text-align: center;"><strong><em>Number of Vesicles</em></strong></th>
<th style="text-align: center;"><strong><em>TP</em></strong></th>
<th style="text-align: center;"><strong><em>FN</em></strong></th>
<th style="text-align: center;"><strong><em>FP</em></strong></th>
<th style="text-align: center;"><strong><em>F1-score</em></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">N 134</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">2.73±2.53</td>
<td style="text-align: center;">629</td>
<td style="text-align: center;">530</td>
<td style="text-align: center;">99</td>
<td style="text-align: center;">79</td>
<td style="text-align: center;">0.856</td>
</tr>
<tr class="even">
<td style="text-align: center;">N 80</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.78±2.73</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">101</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">0.902</td>
</tr>
<tr class="odd">
<td style="text-align: center;">N 73</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">3.14±2.77</td>
<td style="text-align: center;">510</td>
<td style="text-align: center;">480</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">39</td>
<td style="text-align: center;">0.933</td>
</tr>
<tr class="even">
<td style="text-align: center;">N 133</td>
<td style="text-align: center;">0.80</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2.21±2.06</td>
<td style="text-align: center;">516</td>
<td style="text-align: center;">498</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">0.971</td>
</tr>
<tr class="odd">
<td style="text-align: center;">N 116</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.57±2.59</td>
<td style="text-align: center;">294</td>
<td style="text-align: center;">281</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">44</td>
<td style="text-align: center;">0.908</td>
</tr>
<tr class="even">
<td style="text-align: center;">N 84</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">1.6±1.89</td>
<td style="text-align: center;">481</td>
<td style="text-align: center;">464</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">29</td>
<td style="text-align: center;">0.953</td>
</tr>
<tr class="odd">
<td style="text-align: center;">N 115</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">3.41±3.11</td>
<td style="text-align: center;">163</td>
<td style="text-align: center;">130</td>
<td style="text-align: center;">33</td>
<td style="text-align: center;">62</td>
<td style="text-align: center;">0.732</td>
</tr>
<tr class="even">
<td style="text-align: center;">N 102</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.52±0.83</td>
<td style="text-align: center;">103</td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.955</td>
</tr>
<tr class="odd">
<td style="text-align: center;">N 123</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2.3±1.8</td>
<td style="text-align: center;">65</td>
<td style="text-align: center;">59</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">0.908</td>
</tr>
<tr class="even">
<td style="text-align: center;">N 132</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">1.61±1.03</td>
<td style="text-align: center;">135</td>
<td style="text-align: center;">125</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">0.903</td>
</tr>
<tr class="odd">
<td style="text-align: center;">N 114</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.71±2.07</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">115</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">0.868</td>
</tr>
<tr class="even">
<td style="text-align: center;">N 128</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.90</td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">2.11±1.17</td>
<td style="text-align: center;">248</td>
<td style="text-align: center;">239</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">0.937</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>Average</strong></td>
<td style="text-align: center;"><strong>0.71±0.08</strong></td>
<td style="text-align: center;"><strong>0.82±0.08</strong></td>
<td style="text-align: center;"><strong>0.06±0.02</strong></td>
<td style="text-align: center;"><strong>2.39±2.05</strong></td>
<td style="text-align: center;"><strong>281.75</strong></td>
<td style="text-align: center;"><strong>91.83%</strong></td>
<td style="text-align: center;"><strong>8.17%</strong></td>
<td style="text-align: center;"><strong>11.22%</strong></td>
<td style="text-align: center;"><strong>0.902±0.064</strong></td>
</tr>
</tbody>
</table>
</div>
<div id="fig:dice-improv" class="fignos">
<figure>
<img src="images/multi_panel_plot_vertical_new.png" style="width:15cm" alt="Figure 4: Dice development during post-processing. Dice development at different post-processing steps of initially predicted mask (different colors correspond to different tomograms): A) synaptosomal train set B) synaptosomal test set c) neuronal generalization test set" />
<figcaption aria-hidden="true"><span>Figure 4:</span> <strong>Dice development during post-processing</strong>. Dice development at different post-processing steps of initially predicted mask (different colors correspond to different tomograms): A) synaptosomal train set B) synaptosomal test set c) neuronal generalization test set</figcaption>
</figure>
</div>
<h3 id="downstream-analysis-and-application">Downstream analysis and application</h3>
<p>Traditional manual segmentation, while precise, is time-consuming and often limited in scope.
In previous cryo-ET studies of presynaptic terminals, the analysis of spatial organization was restricted within 250 nm of the active zone in order to keep segmentation time reasonable.
This limitation inherently narrows the scope of synaptic analyses.
The advent of deep learning-based segmentation offers a promising alternative, providing both speed and scalability.
We were able to segment full synapses in a fraction of the time that it manual segmentation would take.
Furthermore, we have implemented an interactive tool with Napari <span class="citation" data-cites="YEMgt2T4">[<a href="#ref-YEMgt2T4" role="doc-biblioref">21</a>]</span> that enables to swiftly rectify false positives and negatives by adding or removing vesicles as needed, ensuring the highest level of accuracy in the final segmented output.
A comparison of manual and automatic segmentation is shown in Figure <a href="#fig:pipelineontomo">5</a>.</p>
<div id="fig:pipelineontomo" class="fignos">
<figure>
<img src="images/synaptasome-new.png" style="width:15cm" alt="Figure 5: Comparison of manual and automatic vesicle segmentation. A: 3D representation of a synaptasome density map, visualized in an orthogonal view.B: Probability map output by the neural network. The map is represented with a color gradient ranging from blue (0.9968) to red (1), indicating the likelihood of synaptic vesicle presence. C: Segmentation after global threshold optimization. D: The final representation of synaptic vesicle segmentation post-processing. CryoVesNet segmented vesicles are depicted in light blue, combined with expert annotation in yellow (restricted within 250 nm of the active zone shown in red). Bar, 100 nm." />
<figcaption aria-hidden="true"><span>Figure 5:</span> <strong>Comparison of manual and automatic vesicle segmentation</strong>. A: 3D representation of a synaptasome density map, visualized in an orthogonal view.B: Probability map output by the neural network. The map is represented with a color gradient ranging from blue (0.9968) to red (1), indicating the likelihood of synaptic vesicle presence. C: Segmentation after global threshold optimization. D: The final representation of synaptic vesicle segmentation post-processing. CryoVesNet segmented vesicles are depicted in light blue, combined with expert annotation in yellow (restricted within 250 nm of the active zone shown in red). Bar, 100 nm.</figcaption>
</figure>
</div>
<p>Pyto is a software package designed for the analysis of pleomorphic membrane-bound molecular complexes in 3D images, particularly in the context of synaptic cryo-ET.
A key feature of Pyto is its ability to accurately segment connectors and tethers within the pre-synaptic terminal, a task that requires a high level of vesicle segmentation precision.
This segmentation process is hierarchical and connectivity-based, detecting densities interconnecting vesicles (connectors) and densities connecting vesicles to the active-zone plasma membrane (tethers).
CryoVesNet has been designed to be compatible with Pyto and an application is demonstrated in Figure <a href="#fig:amira">6</a>.
This enables us to extract a wealth of structural information to better understand the structural basis of synaptic vesicle exocytosis regulation.</p>
<div id="fig:amira" class="fignos">
<figure>
<img src="images/neuron_amira_new.png" style="width:15cm" alt="Figure 6: 3D model of a cultured mouse neuron synapse. A: slice through a tomogram. B: Segmentation of plasma membrane (light blue), mitochondria (dark blue), endosomes (green), microtubules (dark magenta). C: Vesicles (yellow) and connectors (pink) segmented with CryoVesNet and Pyto, respectively. D: Combination of B and C. Bar, 100 nm." />
<figcaption aria-hidden="true"><span>Figure 6:</span> <strong>3D model of a cultured mouse neuron synapse</strong>. A: slice through a tomogram. B: Segmentation of plasma membrane (light blue), mitochondria (dark blue), endosomes (green), microtubules (dark magenta). C: Vesicles (yellow) and connectors (pink) segmented with CryoVesNet and Pyto, respectively. D: Combination of B and C. Bar, 100 nm.</figcaption>
</figure>
</div>
<h2 id="discussion">Discussion</h2>
<h3 id="synaptic-vesicles-molecular-interactions-and-functions">Synaptic Vesicles: Molecular Interactions and Functions</h3>
<p>Synaptic vesicles (SVs) play a central role in neurotransmission, facilitating the release of neurotransmitters into the synaptic cleft.
These vesicles undergo a series of molecular interactions with various protein complexes, transitioning from a tethered to a primed state, and eventually to neurotransmitter release through exocytosis.
Synapsins have been identified as key proteins in regulating the availability of SVs for exocytosis.
It has been hypothesized that synapsins cross-link SVs, thereby preventing their premature release.</p>
<p>Cryo-ET emerges as a powerful tool to address these challenges, offering unparalleled insights into the molecular architecture of synapses.
Accurate segmentation of structures such as vesicles, connectors, and tethers is essential for a comprehensive understanding of synaptic function.
Cryo-ET, however, is not without its challenges.
The technique suffers from a high level of noise and anisotropic resolution (known as the missing wedge phenomenon), which complicates data analysis and interpretation.
Addressing these challenges is crucial for obtaining clear and accurate tomographic reconstructions.</p>
<h3 id="cryovesnet-automatic-vesicle-segmentation-in-cryo-et">CryoVesNet: Automatic Vesicle Segmentation in Cryo-ET</h3>
<p>By utilizing a U-Net architecture trained on manually segmented tomograms and postprocessing steps, we have developed a system that can efficiently and accurately segment synaptic vesicles in tomographic datasets.
In particular, CryoVesNet is uniquely insensitive to the missing wedge and can segment complete vesicles even if the membrane is not fully visible in the tomogram.
The results obtained from our method, as evidenced by the Dice coefficient and other evaluation metrics, demonstrate its robustness and accuracy.
Notably, our method ability to generalize across different datasets, namely from rat synaptosomes and to primary neuronal cultures, underscores its versatility and potential for widespread application.
It is not restricted to synaptic vesicles but can be applied to any spherical membrane-bound organelle.
It is interesting to note that the Dice coefficient of the U-Net output (probability mask) was better for the test set and generalization set than the train set.
Consequently the train set benefited more strongly from the post-processing steps than the test and generalization sets in term of Dice coefficient.</p>
<p>The use of both global and adaptive localized thresholding techniques further refines the segmentation, addressing challenges posed by closely packed vesicles.
Our results highlight the effectiveness of our post-processing steps, including radial profile refinement and the removal of outliers.
The radial profile, in particular, ensures that the segmented vesicles closely match their actual structure in the tomogram, providing a more accurate representation.
Furthermore, our method compatibility with software like Pyto, which is designed for the analysis of pleomorphic membrane-bound molecular complexes in 3D images, enhances its utility.
By integrating our segmentation approach with tools like Pyto, researchers can gain deeper insights into vesicle interactions.
Significantly, with minimal adjustments, our method could be adapted to achieve highly precise segmentation of any membrane-enclosed organelle or the plasma membrane itself.</p>
<h3 id="conclusion">Conclusion</h3>
<p>In conclusion, CryoVesNet for automatic segmentation in cryo-ET represents a significant step forward in the study of synaptic vesicles and their associated structures.
By combining the power of deep learning with optimized post-processing techniques, we offer a solution that is both efficient and precise.
As the field of structural cell biology continues to evolve, tools like ours will play a crucial role in advancing our understanding of complex cellular structures and processes.</p>
<h2 id="materials-and-methods">Materials and methods</h2>
<h3 id="cryo-electron-tomography-datasets">Cryo-electron tomography datasets</h3>
<p>In this study, we used datasets originating from either rat synaptosomes or mouse primary neuron cultures.
They represent a total of 30 tomograms with heterogeneous pixel sizes, defocus and resolution and we split them in three groups:
1. Train set: 9 synaptosome tomograms were used for training.
2. Test set: 9 independent synaptosome tomograms were used for testing.
3. Generalization test set: 12 neuron tomograms were used for assessing transfer learning potential.
The preparation procedure of the samples from which the datasets were obtained as well as the biological analysis of these datasets was previously reported <span class="citation" data-cites="CERJ8H0p">[<a href="#ref-CERJ8H0p" role="doc-biblioref">22</a>]</span>.</p>
<h3 id="manual-segmentation-and-automatic-interboundary-segment-detection">Manual segmentation and automatic interboundary segment detection</h3>
<p>Manual segmentation of SVs, the presynaptic cytoplasm, and the active zone plasma membrane was done in IMOD <span class="citation" data-cites="136NHHp17">[<a href="#ref-136NHHp17" role="doc-biblioref">20</a>]</span>.
SVs were segmented as spheres.
The presynaptic cytoplasm marked the region to be analyzed by Pyto <span class="citation" data-cites="1HtRUUZQi">[<a href="#ref-1HtRUUZQi" role="doc-biblioref">9</a>]</span>.
Later on, we refer to this region as the cytoplasmic segmentation region.
It consisted of the volume comprising the active zone and the cluster of SVs.
The analysis by Pyto was essentially the same as described previously <span class="citation" data-cites="XQJ3R1HJ 1HtRUUZQi">[<a href="#ref-XQJ3R1HJ" role="doc-biblioref">5</a>,<a href="#ref-1HtRUUZQi" role="doc-biblioref">9</a>]</span>.
In short, the segmented region is divided in 1 voxel thick layers parallel to the active zone for distance calculations.
A hierarchical connectivity segmentation detects densities interconnecting boundaries.
The boundaries were synaptic vesicles and the active zone plasma membrane.
Detected intervesicular segments are termed connectors and segments connecting vesicles to the active zone plasma membrane are called tethers.
Distance calculations respective to SVs were done from SV center.
The segmentation procedure is conservative and tends to miss some tethers and connectors because of noise.
Consequently, the numbers of tethers and connectors should not be considered as absolute values, but rather to compare experimental groups.
As it was done before, an upper limit was set between 2100 and 3200 nm<sup>3</sup> on segment volume.
The tomograms that were used for this analysis were binned by a factor of 2 to 3, resulting in voxel sizes between 2.1 and 2.4 nm.</p>
<h3 id="train-and-validation-set-generation">Train and validation set generation</h3>
<p>In the preparation of our train set, we utilized segmented 3D image volumes.
The primary volume was systematically divided into 32<sup>3</sup> cubic sub-volumes.
To ensure the relevance and richness of the data, only those sub-volumes that were sufficiently occupied by vesicles, specifically containing more than 1000 voxels, were retained.
860 sub-volumes were used for training and 100 sub-volumes were used for validation.</p>
<h3 id="network-architecture-and-training-procedure">Network architecture and training procedure</h3>
<p>We used a U-Net with two downsampling stages and two convolutional layers per stages, with a kernel size of 3, and ReLU activation function based on the open-source CARE framework (Figure <a href="#fig:pipeline">1</a>) <span class="citation" data-cites="12G712Zky">[<a href="#ref-12G712Zky" role="doc-biblioref">18</a>]</span>.
We used the Adam optimizer on a binary cross-entropy loss function.
The learning progress was tracked by calculating the Dice coefficient and the loss value after each training epoch (Figure <a href="#fig:dice">EV2</a>).
The Dice coefficient for the train set was initially ~0.25 and rose to over 0.9 after approximately 50 epochs, while for the validation set, it increased to 0.8.
The loss for the train set went from 0.55 and to values below 0.05 after 50 epochs while for the validation set it went from 1 and to slightly below 0.3 after the initial 50 epochs and then rose slightly.
The training was done for 200 epochs.</p>
<h3 id="probability-map-construction">Probability map construction</h3>
<p>Our U-Net model, trained on 32<sup>3</sup>-voxel patches, utilizes a 24-voxel region of interest (ROI).
To mitigate tiling effects during testing, the network input can be expanded to accommodate larger volume specifically in this case 64<sup>3</sup> voxels.
The tomogram undergoes padding to align with the ROI, ensuring reduced edge artifacts.
Segmentation is executed in tiles, where the U-Net predicts the synaptic vesicle probability for each tile.
Only the central part of the segmented patch, corresponding to the ROI, is retained.
Finally, the segmented tiles are reassembled, yielding a continuous synaptic vesicle probability map of the entire volume.</p>
<h3 id="global-thresholding">Global thresholding</h3>
<p>Segmenting implies turning the probability map into a binary mask.
In order to find the optimal threshold value, we iterated through potential threshold values ranging from 0.8 to 1 in increments of 0.01.
A binary mask was generated for each threshold.
Subsequently, an erosion operation was applied to the binary mask, and the difference between the original and eroded masks produced the vesicle shell.
The voxel intensity values of the original image corresponding to this shell were recorded for each threshold.
We minimized the average intensity of the shell voxels to determine the optimal threshold value, since the shell of correctly segmented vesicles corresponds to the vesicle membrane, which in cryo-ET appears darker, i.e., with lower intensity values.</p>
<h3 id="adaptative-local-thresholding">Adaptative local thresholding</h3>
<p>Each individual segment was given a label using the <code>scikit-image label</code> method <span class="citation" data-cites="stvWEJeu">[<a href="#ref-stvWEJeu" role="doc-biblioref">23</a>]</span>.
A majority of vesicles were correctly segmented but we noticed some segments included more than one vesicle.
We therefore evaluated each segment with two criteria based on the fact that synaptic vesicles have a homogenous size and are spherical.
Firstly we calculated the volume z-score <span class="math inline">\(z\)</span> for each segment:
<span id="eq:z-score-volume" class="eqnos"><span class="math display">\[z(S_i) = \frac{V(S_i) - \mu}{\sigma}\]</span><span class="eqnos-number">(1)</span></span>
where <span class="math inline">\(S_i\)</span> is the segment <span class="math inline">\(i\)</span>, <span class="math inline">\(V(S_i)\)</span> is the volume of <span class="math inline">\(S_i\)</span>, <span class="math inline">\(\mu\)</span> the average volume of all segments, and <span class="math inline">\(\sigma\)</span> the standard deviation of the segment volumes.
Secondly, we computed the segment extent <span class="math inline">\(e\)</span> as:
<span id="eq:extent" class="eqnos"><span class="math display">\[e(S_i) = \frac{V(S_i)}{B(S_i)}\]</span><span class="eqnos-number">(2)</span></span>
where <span class="math inline">\(B(S_i)\)</span> is the volume of segment <span class="math inline">\(i\)</span> bounding box.
The extent of a sphere equals <span class="math inline">\(\frac{\pi}{6}\)</span>.
Segments with both a z-score <span class="math inline">\(z &gt; 1\)</span> and an extent <span class="math inline">\(e &lt; 0.25\)</span> were considered as potentially comprising more than one vesicle.
For each of these segments, the threshold was increased stepwise until two distinct segments were generated.
Subsequently, the extent and volume of all segments was evaluated again. Any segment with <span class="math inline">\(e &lt; 0.25\)</span>, or <span class="math inline">\(e &gt; 0.75\)</span>, or <span class="math inline">\(V &lt; k\)</span> was discarded.
<span class="math inline">\(k\)</span> was defined as the volume of a sphere with a radius of 12 nm.
This ensured that segments deviating highly from spherical shape and segments with a volume smaller than an acceptable volume <span class="math inline">\(k\)</span> were removed.</p>
<h3 id="segmentation-refinement-using-radial-profile">Segmentation refinement using radial profile</h3>
<p>Even if most synaptic vesicles were detected and well segmented, segmentation accuracy was not sufficient for our downstream application.
To improve accuracy, each segment was converted to a spherical segment and its radius and position was refined.
Initial spherical conversion was done by setting the center of the sphere <span class="math inline">\(C\)</span> at the position of the centroid of the segment, while the radius <span class="math inline">\(r\)</span> was defined as half the length of the bounding box longest edge.
The segment position and radius were iteratively refined as follows.</p>
<ol type="1">
<li><p>The radial average <span class="math inline">\(\langle I(d)\rangle\)</span> was computed:
<span id="eq:radial_average" class="eqnos"><span class="math display">\[\langle I(d)\rangle = \frac{1}{4\pi ^2 r^2} \int_{0}^{2\pi}\int_{0}^{2\pi}I(d,\theta ,\phi) \, d\phi \, d\theta\]</span><span class="eqnos-number">(3)</span></span>
where <span class="math inline">\(d\)</span> is the radial distance from the segment center, <span class="math inline">\(\theta\)</span> the polar angle, and <span class="math inline">\(\phi\)</span> the azimuthal angle.</p></li>
<li><p>The radius of the vesicle <span class="math inline">\(r\)</span> was updated as:
<span id="eq:vesicle_radius" class="eqnos"><span class="math display">\[r = d_m + \frac{t_m}{2}\]</span><span class="eqnos-number">(4)</span></span>
where <span class="math inline">\(d_m\)</span> is the radial distance of center of the vesicle membrane, and <span class="math inline">\(t_m\)</span> the thickness of the vesicle membrane.
<span class="math inline">\(d_m\)</span> was defined as the radial distance for which the radial average was minimal.
<span class="math inline">\(\frac{t_m}{2}\)</span> was calculated as the distance between the center of the vesicle membrane and the minimum of the second derivative of the radial profile in the interval between the center of the vesicle membrane and the maximum of the Fresnel fringe outside the membrane.</p></li>
<li><p>The radial average was back projected in 3-dimension:
<span id="eq:3d-average" class="eqnos"><span class="math display">\[I(x,y,z) =  \langle I(\sqrt{x^2+y^2+z^2})\rangle\]</span><span class="eqnos-number">(5)</span></span>
where <span class="math inline">\((x,y,z)=(0,0,0)\)</span> is the coordinate of the segment center.</p></li>
<li><p>We computed by cross-correlation the shift between the obtained 3-D average and the 3-D image in the cubic box with central coordinates <span class="math inline">\(C\)</span> and edge length <span class="math inline">\(l = 2r + c\)</span>, where <span class="math inline">\(c\)</span> is a constant.
<span class="math inline">\(C\)</span> was updated by subtraction of the shift.</p></li>
<li><p>Steps 1 to 4 were repeated for a maximum of 10 iterations until convergence or until a total shift of <span class="math inline">\(\frac{1}{2}\sqrt{3l_o^2}\)</span>, where <span class="math inline">\(l_o\)</span> is the edge length of the initial box.
The feature space of predicted vesicle labels was computed, containing membrane thickness <span class="math inline">\(t_m\)</span>, membrane intensity <span class="math inline">\(\rho\)</span>, and vesicle radius <span class="math inline">\(r\)</span>.
<span class="math inline">\(\rho\)</span> was defined as the mean intensity of the radial average within the radial distance interval <span class="math inline">\([d_m - \frac{t_m}{2}\,,\,d_m + \frac{t_m}{2}]\)</span>.</p></li>
</ol>
<h3 id="outlier-detection-and-refinement-1">Outlier detection and refinement</h3>
<p>Following radial profile calculation, key features, namely thickness, radius, and membrane intensity, were extracted.
Using these criteria, the Mahalanobis distance <span class="math inline">\(D^2\)</span> was calculated for each data point to quantify its distance from the distribution of these features as follows, using Scipy’s implementation <span class="citation" data-cites="hFc1Q2c">[<a href="#ref-hFc1Q2c" role="doc-biblioref">24</a>]</span>:
<span id="eq:mahalanobis-distance" class="eqnos"><span class="math display">\[D^2 = (\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{S}^{-1} (\mathbf{x} - \boldsymbol{\mu})\]</span><span class="eqnos-number">(6)</span></span>
where <span class="math inline">\(\mathbf{x}\)</span> is the vector of the three features, <span class="math inline">\(\boldsymbol{\mu}\)</span> is the mean vector of the features, and <span class="math inline">\(\mathbf{S}^{-1}\)</span> is the inverse covariance matrix of the features.
The significance of the Mahalanobis distance was interpreted as follows:
<span id="eq:p-value" class="eqnos"><span class="math display">\[p = 1 - \text{CDF}_{\chi^2}(D^2, \nu)\]</span><span class="eqnos-number">(7)</span></span>
where <span class="math inline">\(\text{CDF}_{\chi^2}\)</span> is the cumulative distribution function of the chi-squared distribution, and <span class="math inline">\(\nu\)</span> is the number of degrees of freedom, which is equal to the number of features - 1.
The resulting p-value provides a measure of the statistical significance of each data point’s distance (Figure <a href="#fig:outlier">3</a>).</p>
<p>With the computed p-values, outlier detection and refinement were conducted.
Each vesicle with a p-value lower than a given threshold was defined as an outlier.
In this study, we empirically set the threshold to 0.3, but other values can be used, depending on the use case.
The radial profile and p-value of the outliers was recalculated using a different box size.
We performed this step iteratively.
At each iteration the box size was made larger by 2x2x2 voxels.
For each outlier, the iteration stopped when its p-value was higher than the threshold.
A maximum of 10 iterations was performed.
Vesicles that did not meet the p-value criteria were removed from the dataset.</p>
<h3 id="evaluation-metrics">Evaluation Metrics</h3>
<p>The evaluation framework was designed to assess the capabilities of the proposed toolbox for automatic synaptic vesicle segmentation.
We defined as ground truth the manual segmentation of synaptic vesicles.
Evaluation was peformed within the cytoplasmic segmentation region (see “Manual segmentation and automatic interboundary segment detection”).
We performed per vesicle evaluation and voxel-wise evaluation.
For the former, we defined a vesicle as correctly segmented if the center of the predicted vesicle was located inside the ground truth vesicle.
Based on that we calculated an F1 score.
For the voxel-wise evaluation, we calculated the Dice coefficient between prediction and the ground truth.</p>
<h4 id="voxel-wise-evaluation">Voxel-wise evaluation</h4>
<p>During training a Dice coefficient for probabilistic subvolume maps was calculated after each epoch as a performance quantification <a href="#fig:dice">EV2</a>.
After reconstructing the probablility map after training or prediction, we employed the Dice metric for the whole tomogram to evaluate the similarity of the predicted probability mask with ground truth <a href="#tbl:train-tomograms">1</a>,<a href="#tbl:test-tomograms">2</a>, and <a href="#tbl:neuron-tomograms">3</a>.
The Dice coefficient is defined as:</p>
<p><span id="eq:dice" class="eqnos"><span class="math display">\[1-\frac{2\sum_{voxels} y_{true} y_{pred}}{\sum_{voxels} y_{true}^2+\sum_{voxels} y_{pred}^2}\]</span><span class="eqnos-number">(8)</span></span> </p>
<p>where <span class="math inline">\(y_{true}\)</span> and <span class="math inline">\(y_{pred}\)</span> are the ground truth and predicted probability values, respectively, for each voxel.</p>
<p>The Dice coefficient was also employed to monitor all stages of post-processing of the labels, to observe the effect of each post-processing step.</p>
<h4 id="vesicle-diameter-and-position-deviation">Vesicle diameter and position deviation</h4>
<p>In addition to the F1-score, we also evaluated the precision of our segmentation by calculating the deviation of the estimated vesicle diameter and position from the ground truth.
Given the diameter of a ground-truth manually segmented vesicles <span class="math inline">\(d_{GTi}\)</span> and the predicted diameters of the same vesicles <span class="math inline">\(d_{Pi}\)</span>, the average deviation in diameter estimation across all vesicles can be expressed as <span class="math inline">\(\delta_d\)</span>, where <span class="math inline">\(\delta_d\)</span> is calculated as:
<span id="eq:delta_d-equation" class="eqnos"><span class="math display">\[\delta_d = \frac{1}{n} \sum_{i=1}^{n} \left( 1 - \frac{\min(dPi, dGTi)}{\max(dPi, dGTi)} \right)\]</span><span class="eqnos-number">(9)</span></span>
Here, n represents the total number of vesicles, <span class="math inline">\(dPi\)</span> is the diameter of i-th vesicle predicted by the segmentation, and <span class="math inline">\(dGTi\)</span> is the diameter of the i-th vesicle in the ground truth.
This formula offers an insight into the congruence between our estimated diameter and the manual segmentation, with a diminished value of <span class="math inline">\(\delta d\)</span> signifying a closer approximation.</p>
<p>Similarly, the average deviation in position estimation across all vesicles can be expressed as <span class="math inline">\(\Delta_c\)</span>.
It corresponds to the average euclidean distance between the center of ground truth vesicles and the center of predicted vesicles.</p>
<h3 id="statistical-comparison">Statistical comparison</h3>
<p>Multiple pairwise ANOVA comparisons with Benjamini-Hochberg correction were performed on the Dice values summarized in <a href="#tbl:dice-statistics">EV1</a> to assess the statistical significance of the differences between the Dice values <span class="citation" data-cites="UeFCwwR7">[<a href="#ref-UeFCwwR7" role="doc-biblioref">25</a>]</span>.
We performed Benjamini-Hochberg correction with the <em>multipletests</em> function implemented in the Python module <em>statsmodels</em> <span class="citation" data-cites="15kEEkiul">[<a href="#ref-15kEEkiul" role="doc-biblioref">26</a>]</span>.
A list of P-values resulting form pairwise comparisons was input, and <em>multipletests</em> output a list of corrected P-values.
The used implementation of the Benjamini-Hochberg correction does not require a false discovery rate to be input.
This variation of the original Benjamini-Hochberg correction algorithm was proposed by Yekutieli and Benjamini <span class="citation" data-cites="ibSnzEjI">[<a href="#ref-ibSnzEjI" role="doc-biblioref">27</a>]</span>.
If a corrected P-value is smaller than the defined acceptable false discovery rate, then the null hypothesis is rejected, i.e. the difference is considered statistically significant.
This algorithm enables to test multiple false discovery rates in one step and its conclusions are exactly the same as the original Benjamini-Hochberg correction algorithm run multiple times with different false discovery rates.</p>
<h3 id="computational-setup">Computational Setup</h3>
<p>All experiments were conducted using 4 x NVIDIA 2080 Ti GPUs with CUDA 10.1.
The software environment was set up with Python 3.
Key libraries and packages used include TensorFlow 2.4.1 with GPU support and Keras 2.4.3.
Image visualization was achieved with UCSF ChimeraX <span class="citation" data-cites="k53Adxgo">[<a href="#ref-k53Adxgo" role="doc-biblioref">28</a>]</span> and Amira 2022.2 (Thermofisher Scientific).
Surface rendering was performed by the volume tracer and color zone in UCSF ChimeraX.</p>
<h3 id="manuscript-preparation">Manuscript preparation</h3>
<p>The manuscript was written with the open and collaborative scientific writing package Manubot <span class="citation" data-cites="YuJbg3zO">[<a href="#ref-YuJbg3zO" role="doc-biblioref">29</a>]</span>.
The source code and data for this manuscript are available at <a href="https://github.com/aseedb/synaptic_tomo_ms" class="uri">https://github.com/aseedb/synaptic_tomo_ms</a>.</p>
<h3 id="code-availability">Code availability</h3>
<p>CryoVesNet is available on GitHub at <a href="https://github.com/Zuber-group/CryoVesNet" class="uri">https://github.com/Zuber-group/CryoVesNet</a></p>
<h2 id="author-contributions">Author contributions</h2>
<p>BZ designed and supervised the study.
RS and JR prepared samples, and acquired the data, reconstructed tomograms, and performed manual segmentation.
AK, GW and BZ developed the CryoVesNet package.
AK performed data analysis.
JBS provided the SNAP-25 KO and mutant mice.
RS and AK wrote the initial draft of the manuscript.
AK, RS wrote the manuscript with contribution from all authors.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>This work was supported by the Swiss National Science Foundation (grant number 179520 to BZ), ERA-NET NEURON (NEURON-119 to BZ), and by the University of Bern Research Foundation (to Ioan Iacovache).</p>
<h2 id="disclosure-and-competing-interests-statement">Disclosure and competing interests statement</h2>
<p>The authors declare no competing interests.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-IpfJPPLG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><strong>Towards Visual Proteomics at High Resolution</strong> <div class="csl-block">Felix JB Bäuerlein, Wolfgang Baumeister</div> <em>Journal of Molecular Biology</em> (2021-10) <a href="https://doi.org/gn9t3v">https://doi.org/gn9t3v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jmb.2021.167187">10.1016/j.jmb.2021.167187</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34384780">34384780</a></div></div>
</div>
<div id="ref-2TrAHWcN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><strong>Exploring high-resolution cryo-ET and subtomogram averaging capabilities of contemporary DEDs</strong> <div class="csl-block">Martin Obr, Wim JH Hagen, Robert A Dick, Lingbo Yu, Abhay Kotecha, Florian KM Schur</div> <em>Cold Spring Harbor Laboratory</em> (2022-01-10) <a href="https://doi.org/gn92pd">https://doi.org/gn92pd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/2022.01.10.475481">10.1101/2022.01.10.475481</a></div></div>
</div>
<div id="ref-EGfvt7aR" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><strong>High-resolution in situ structure determination by cryo-electron tomography and subtomogram averaging using emClarity</strong> <div class="csl-block">Tao Ni, Thomas Frosio, Luiza Mendonça, Yuewen Sheng, Daniel Clare, Benjamin A Himes, Peijun Zhang</div> <em>Nature Protocols</em> (2022-01-12) <a href="https://doi.org/gn92pc">https://doi.org/gn92pc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41596-021-00648-5">10.1038/s41596-021-00648-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/35022621">35022621</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9251519">PMC9251519</a></div></div>
</div>
<div id="ref-WmTa9taa" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><strong>STRUCTURAL STUDIES BY ELECTRON TOMOGRAPHY: From Cells to Molecules</strong> <div class="csl-block">Vladan Lučić, Friedrich Förster, Wolfgang Baumeister</div> <em>Annual Review of Biochemistry</em> (2005-06-01) <a href="https://doi.org/cfd27f">https://doi.org/cfd27f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1146/annurev.biochem.73.011303.074112">10.1146/annurev.biochem.73.011303.074112</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15952904">15952904</a></div></div>
</div>
<div id="ref-XQJ3R1HJ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><strong>Quantitative analysis of the native presynaptic cytomatrix by cryoelectron tomography</strong> <div class="csl-block">Rubén Fernández-Busnadiego, Benoît Zuber, Ulrike Elisabeth Maurer, Marek Cyrklaff, Wolfgang Baumeister, Vladan Lučić</div> <em>Journal of Cell Biology</em> (2010-01-11) <a href="https://doi.org/b9c26b">https://doi.org/b9c26b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1083/jcb.200908082">10.1083/jcb.200908082</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20065095">20065095</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2812849">PMC2812849</a></div></div>
</div>
<div id="ref-kjMcXSJ3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><strong>Morphofunctional changes at the active zone during synaptic vesicle exocytosis</strong> <div class="csl-block">Julika Radecke, Raphaela Seeger, Anna Kádková, Ulrike Laugks, Amin Khosrozadeh, Kenneth N Goldie, Vladan Lučić, Jakob B Sørensen, Benoît Zuber</div> <em>EMBO reports</em> (2023-03-06) <a href="https://doi.org/gsx7nw">https://doi.org/gsx7nw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.15252/embr.202255719">10.15252/embr.202255719</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/36876590">36876590</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10157379">PMC10157379</a></div></div>
</div>
<div id="ref-K10hpz3n" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><strong>Molecular architecture of the presynaptic terminal</strong> <div class="csl-block">Benoît Zuber, Vladan Lučić</div> <em>Current Opinion in Structural Biology</em> (2019-02) <a href="https://doi.org/gk8gpd">https://doi.org/gk8gpd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.sbi.2019.01.008">10.1016/j.sbi.2019.01.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30925443">30925443</a></div></div>
</div>
<div id="ref-Lw7FpxSz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline"><strong>Neurons as a model system for cryo-electron tomography</strong> <div class="csl-block">Benoît Zuber, Vladan Lučić</div> <em>Journal of Structural Biology: X</em> (2022) <a href="https://doi.org/gqc4n2">https://doi.org/gqc4n2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.yjsbx.2022.100067">10.1016/j.yjsbx.2022.100067</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/35310407">35310407</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8924422">PMC8924422</a></div></div>
</div>
<div id="ref-1HtRUUZQi" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline"><strong>Hierarchical detection and analysis of macromolecular complexes in cryo-electron tomograms using Pyto software</strong> <div class="csl-block">Vladan Lučić, Rubén Fernández-Busnadiego, Ulrike Laugks, Wolfgang Baumeister</div> <em>Journal of Structural Biology</em> (2016-12) <a href="https://doi.org/f9d5t2">https://doi.org/f9d5t2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jsb.2016.10.004">10.1016/j.jsb.2016.10.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27742578">27742578</a></div></div>
</div>
<div id="ref-JWuvfT0Z" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><strong>Robust membrane detection based on tensor voting for electron tomography</strong> <div class="csl-block">Antonio Martinez-Sanchez, Inmaculada Garcia, Shoh Asano, Vladan Lucic, Jose-Jesus Fernandez</div> <em>Journal of Structural Biology</em> (2014-04) <a href="https://doi.org/f5zkj8">https://doi.org/f5zkj8</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jsb.2014.02.015">10.1016/j.jsb.2014.02.015</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24625523">24625523</a></div></div>
</div>
<div id="ref-GNLHO53d" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline"><strong>Convolutional neural networks for automated annotation of cellular cryo-electron tomograms</strong> <div class="csl-block">Muyuan Chen, Wei Dai, Stella Y Sun, Darius Jonasch, Cynthia Y He, Michael F Schmid, Wah Chiu, Steven J Ludtke</div> <em>Nature Methods</em> (2017-08-28) <a href="https://doi.org/gkpj62">https://doi.org/gkpj62</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nmeth.4405">10.1038/nmeth.4405</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28846087">28846087</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5623144">PMC5623144</a></div></div>
</div>
<div id="ref-RdPTGoZx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline"><strong>Automated Detection and Localization of Synaptic Vesicles in Electron Microscopy Images</strong> <div class="csl-block">Barbara Imbrosci, Dietmar Schmitz, Marta Orlando</div> <em>eneuro</em> (2022-01) <a href="https://doi.org/gn9n8k">https://doi.org/gn9n8k</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1523/eneuro.0400-20.2021">10.1523/eneuro.0400-20.2021</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34983830">34983830</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8805189">PMC8805189</a></div></div>
</div>
<div id="ref-pMX2OxF7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline"><strong>A machine learning pipeline for membrane segmentation of cryo-electron tomograms</strong> <div class="csl-block">Li Zhou, Chao Yang, Weiguo Gao, Talita Perciano, Karen M Davies, Nicholas K Sauter</div> <em>Journal of Computational Science</em> (2023-01) <a href="https://doi.org/gsbxkz">https://doi.org/gsbxkz</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jocs.2022.101904">10.1016/j.jocs.2022.101904</a></div></div>
</div>
<div id="ref-xhywoibB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline"><strong>Convolutional networks for supervised mining of molecular patterns within cellular context</strong> <div class="csl-block">Irene de Teresa-Trueba, Sara K Goetz, Alexander Mattausch, Frosina Stojanovska, Christian E Zimmerli, Mauricio Toro-Nahuelpan, Dorothy WC Cheng, Fergus Tollervey, Constantin Pape, Martin Beck, … Judith B Zaugg</div> <em>Nature Methods</em> (2023-01-23) <a href="https://doi.org/grqqwc">https://doi.org/grqqwc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-022-01746-2">10.1038/s41592-022-01746-2</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/36690741">36690741</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9911354">PMC9911354</a></div></div>
</div>
<div id="ref-VobzV1Lb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline"><strong>Deep learning improves macromolecule identification in 3D cellular cryo-electron tomograms</strong> <div class="csl-block">Emmanuel Moebel, Antonio Martinez-Sanchez, Lorenz Lamm, Ricardo D Righetto, Wojciech Wietrzynski, Sahradha Albert, Damien Larivière, Eric Fourmentin, Stefan Pfeffer, Julio Ortiz, … Charles Kervrann</div> <em>Nature Methods</em> (2021-10-21) <a href="https://doi.org/gm7d6j">https://doi.org/gm7d6j</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-021-01275-4">10.1038/s41592-021-01275-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34675434">34675434</a></div></div>
</div>
<div id="ref-NGTzBMdU" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline"><strong>MemBrain: A deep learning-aided pipeline for detection of membrane proteins in Cryo-electron tomograms</strong> <div class="csl-block">Lorenz Lamm, Ricardo D Righetto, Wojciech Wietrzynski, Matthias Pöge, Antonio Martinez-Sanchez, Tingying Peng, Benjamin D Engel</div> <em>Computer Methods and Programs in Biomedicine</em> (2022-09) <a href="https://doi.org/gs3s63">https://doi.org/gs3s63</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cmpb.2022.106990">10.1016/j.cmpb.2022.106990</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/35858496">35858496</a></div></div>
</div>
<div id="ref-D7hXMn0y" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline"><strong>3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation</strong> <div class="csl-block">Özgün Çiçek, Ahmed Abdulkadir, Soeren S Lienkamp, Thomas Brox, Olaf Ronneberger</div> <em>arXiv</em> (2016-06-22) <a href="https://arxiv.org/abs/1606.06650">https://arxiv.org/abs/1606.06650</a></div>
</div>
<div id="ref-12G712Zky" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline"><strong>Content-aware image restoration: pushing the limits of fluorescence microscopy</strong> <div class="csl-block">Martin Weigert, Uwe Schmidt, Tobias Boothe, Andreas Müller, Alexandr Dibrov, Akanksha Jain, Benjamin Wilhelm, Deborah Schmidt, Coleman Broaddus, Siân Culley, … Eugene W Myers</div> <em>Nature Methods</em> (2018-11-26) <a href="https://doi.org/gfkkfd">https://doi.org/gfkkfd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-018-0216-7">10.1038/s41592-018-0216-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30478326">30478326</a></div></div>
</div>
<div id="ref-vFGVscEl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline"><strong>Cryo-CARE: Content-Aware Image Restoration for Cryo-Transmission Electron Microscopy Data</strong> <div class="csl-block">Tim-Oliver Buchholz, Mareike Jordan, Gaia Pigino, Florian Jug</div> <em>arXiv</em> (2018-10-17) <a href="https://arxiv.org/abs/1810.05420">https://arxiv.org/abs/1810.05420</a></div>
</div>
<div id="ref-136NHHp17" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline"><strong>Computer Visualization of Three-Dimensional Image Data Using IMOD</strong> <div class="csl-block">James R Kremer, David N Mastronarde, JRichard McIntosh</div> <em>Journal of Structural Biology</em> (1996-01) <a href="https://doi.org/d9nfzw">https://doi.org/d9nfzw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1006/jsbi.1996.0013">10.1006/jsbi.1996.0013</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/8742726">8742726</a></div></div>
</div>
<div id="ref-YEMgt2T4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline"><strong>napari: a multi-dimensional image viewer for Python</strong> <div class="csl-block">Jannis Ahlers, Daniel Althviz Moré, Oren Amsalem, Ashley Anderson, Grzegorz Bokota, Peter Boone, Jordão Bragantini, Genevieve Buckley, Alister Burt, Matthias Bussonnier, … Kevin Yamauchi</div> <em>Zenodo</em> (2023-07-05) <a href="https://doi.org/gjpsxz">https://doi.org/gjpsxz</a> <div class="csl-block">DOI: <a href="https://doi.org/10.5281/zenodo.3555620">10.5281/zenodo.3555620</a></div></div>
</div>
<div id="ref-CERJ8H0p" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline"><strong>Morphofunctional changes at the active zone during synaptic vesicle exocytosis</strong> <div class="csl-block">Julika Radecke, Raphaela Seeger, Anna Kádková, Ulrike Laugks, Amin Khosrozadeh, Kenneth N Goldie, Vladan Lučić, Jakob B Sørensen, Benoît Zuber</div> <em>Cold Spring Harbor Laboratory</em> (2022-03-07) <a href="https://doi.org/gpm26v">https://doi.org/gpm26v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/2022.03.07.483217">10.1101/2022.03.07.483217</a></div></div>
</div>
<div id="ref-stvWEJeu" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline"><strong>scikit-image: image processing in Python</strong> <div class="csl-block">Stéfan van der Walt, Johannes L Schönberger, Juan Nunez-Iglesias, François Boulogne, Joshua D Warner, Neil Yager, Emmanuelle Gouillart, Tony Yu</div> <em>PeerJ</em> (2014-06-19) <a href="https://doi.org/gftp3s">https://doi.org/gftp3s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.7717/peerj.453">10.7717/peerj.453</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25024921">25024921</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4081273">PMC4081273</a></div></div>
</div>
<div id="ref-hFc1Q2c" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline"><strong>Author Correction: SciPy 1.0: fundamental algorithms for scientific computing in Python</strong> <div class="csl-block">Pauli Virtanen, Ralf Gommers, Travis E Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, … Paul van Mulbregt</div> <em>Nature Methods</em> (2020-02-24) <a href="https://doi.org/gprj73">https://doi.org/gprj73</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-020-0772-5">10.1038/s41592-020-0772-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32094914">32094914</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7056641">PMC7056641</a></div></div>
</div>
<div id="ref-UeFCwwR7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline"><strong>Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing</strong> <div class="csl-block">Yoav Benjamini, Yosef Hochberg</div> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> (1995-01-01) <a href="https://doi.org/gfpkdx">https://doi.org/gfpkdx</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x">10.1111/j.2517-6161.1995.tb02031.x</a></div></div>
</div>
<div id="ref-15kEEkiul" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline"><strong>Statsmodels: Econometric and Statistical Modeling with Python</strong> <div class="csl-block">Skipper Seabold, Josef Perktold</div> <em>Proceedings of the Python in Science Conference</em> (2010) <a href="https://doi.org/ggq6ff">https://doi.org/ggq6ff</a> <div class="csl-block">DOI: <a href="https://doi.org/10.25080/majora-92bf1922-011">10.25080/majora-92bf1922-011</a></div></div>
</div>
<div id="ref-ibSnzEjI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline"><strong>Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics</strong> <div class="csl-block">Daniel Yekutieli, Yoav Benjamini</div> <em>Journal of Statistical Planning and Inference</em> (1999-12) <a href="https://doi.org/ctfdqf">https://doi.org/ctfdqf</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/s0378-3758(99)00041-5">10.1016/s0378-3758(99)00041-5</a></div></div>
</div>
<div id="ref-k53Adxgo" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline"><strong>&lt;scp&gt;UCSF ChimeraX&lt;/scp&gt;: Tools for structure building and analysis</strong> <div class="csl-block">Elaine C Meng, Thomas D Goddard, Eric F Pettersen, Greg S Couch, Zach J Pearson, John H Morris, Thomas E Ferrin</div> <em>Protein Science</em> (2023-10-20) <a href="https://doi.org/gs72vt">https://doi.org/gs72vt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/pro.4792">10.1002/pro.4792</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/37774136">37774136</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10588335">PMC10588335</a></div></div>
</div>
<div id="ref-YuJbg3zO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline"><strong>Open collaborative writing with Manubot</strong> <div class="csl-block">Daniel S Himmelstein, Vincent Rubinetti, David R Slochower, Dongbo Hu, Venkat S Malladi, Casey S Greene, Anthony Gitter</div> <em>PLOS Computational Biology</em> (2019-06-24) <a href="https://doi.org/c7np">https://doi.org/c7np</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1007128">10.1371/journal.pcbi.1007128</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31233491">31233491</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6611653">PMC6611653</a></div></div>
</div>
</div>
<h2 id="expanded-view">Expanded View</h2>
<h3 id="expanded-view-figures">Expanded View Figures</h3>
<div id="fig:suppl_tom_slice" class="fignos">
<figure>
<img src="images/tomo-scale.svg" style="width:15cm" data-tag="EV1" alt="Figure EV1: A 2D slice of an automatically segmented dataset. A) A section through a presynaptic terminal in a neuron tomogram. B) Predicted probability mask restricted to the segmentation region. Purple corresponds to a low SV probability and yellow to a high SV probability. C) Instance mask of the vesicles after post processing." />
<figcaption aria-hidden="true"><span>Figure EV1:</span> <strong>A 2D slice of an automatically segmented dataset</strong>. A) A section through a presynaptic terminal in a neuron tomogram. B) Predicted probability mask restricted to the segmentation region. Purple corresponds to a low SV probability and yellow to a high SV probability. C) Instance mask of the vesicles after post processing.</figcaption>
</figure>
</div>
<div id="fig:dice" class="fignos">
<figure>
<img src="images/traindice.png" style="width:7cm" data-tag="EV2" alt="Figure EV2: Dice coefficient and loss value for train and validation set." />
<figcaption aria-hidden="true"><span>Figure EV2:</span> <strong>Dice coefficient and loss value for train and validation set.</strong></figcaption>
</figure>
</div>
<h3 id="expanded-view-tables">Expanded View Tables</h3>
<div id="tbl:dice-statistics" class="tablenos">
<table id="tbl:dice-statistics" data-tag="EV1">
<caption><span>Table EV1:</span> <strong>Dice statistical values</strong>. Mean ± standard deviation is shown at each step of the pipeline (Network Probability Mask, Global Threshold, Adaptative Localized Threshold, Sphere Radial Profile Refinement, and Outlier Removal). </caption>
<thead>
<tr class="header">
<th>Algorithm Step</th>
<th>Train set</th>
<th>Test set</th>
<th>Generalization set</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Adaptive Threshold</td>
<td>0.80±0.06</td>
<td>0.83±0.05</td>
<td>0.72±0.11</td>
</tr>
<tr class="even">
<td>Global Threshold</td>
<td>0.80±0.05</td>
<td>0.83±0.05</td>
<td>0.73±0.1</td>
</tr>
<tr class="odd">
<td>Outlier Removal</td>
<td>0.88±0.04</td>
<td>0.85±0.05</td>
<td>0.82±0.08</td>
</tr>
<tr class="even">
<td>Radial Profile</td>
<td>0.87±0.05</td>
<td>0.85±0.05</td>
<td>0.82±0.08</td>
</tr>
<tr class="odd">
<td>Soft Dice</td>
<td>0.80±0.04</td>
<td>0.78±0.03</td>
<td>0.71±0.08</td>
</tr>
<tr class="even">
<td>N</td>
<td>9</td>
<td>9</td>
<td>12</td>
</tr>
</tbody>
</table>
</div>
<p>Multiple, all-against-all ANOVA comparisons were performed with Benjamini-Hochberg correction on the Dice values summarized in EV1. Corrected P-values smaller than 0.05 are shown in bold.</p>
<div id="tbl:dice-pvalues" class="tablenos">
<table id="tbl:dice-pvalues" data-tag="EV2">
<caption><span>Table EV2:</span> <strong>Corrected P-values of Dice values comparisons</strong>. Multiple, all-against-all ANOVA comparisons were performed with Benjamini-Hochberg correction on the Dice values summarized in <a href="#tbl:dice-statistics">EV1</a>. Corrected P-values smaller than 0.05 are shown in bold. </caption>
<colgroup>
<col style="width: 45%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Comparison</th>
<th>Train set</th>
<th>Test set</th>
<th>Generalization set</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Soft Dice vs Global Threshold</td>
<td>0.9360</td>
<td><strong>0.0277</strong></td>
<td>0.8347</td>
</tr>
<tr class="even">
<td>Soft Dice vs Adaptive Threshold</td>
<td>0.9360</td>
<td><strong>0.0277</strong></td>
<td>0.8347</td>
</tr>
<tr class="odd">
<td>Soft Dice vs Radial Profile</td>
<td><strong>0.0083</strong></td>
<td><strong>0.0137</strong></td>
<td><strong>0.0097</strong></td>
</tr>
<tr class="even">
<td>Soft Dice vs Outlier Removal</td>
<td><strong>0.0032</strong></td>
<td><strong>0.0239</strong></td>
<td><strong>0.0097</strong></td>
</tr>
<tr class="odd">
<td>Global Threshold vs Adaptive Threshold</td>
<td>0.9361</td>
<td>0.9366</td>
<td>0.9509</td>
</tr>
<tr class="even">
<td>Global Threshold vs Radial Profile</td>
<td><strong>0.0268</strong></td>
<td>0.7393</td>
<td><strong>0.0370</strong></td>
</tr>
<tr class="odd">
<td>Global Threshold vs Outlier Removal</td>
<td><strong>0.0083</strong></td>
<td>0.7522</td>
<td><strong>0.0370</strong></td>
</tr>
<tr class="even">
<td>Adaptive Threshold vs Radial Profile</td>
<td><strong>0.0276</strong></td>
<td>0.7393</td>
<td><strong>0.0370</strong></td>
</tr>
<tr class="odd">
<td>Adaptive Threshold vs Outlier Removal</td>
<td><strong>0.0083</strong></td>
<td>0.7522</td>
<td><strong>0.0370</strong></td>
</tr>
<tr class="even">
<td>Radial Profile vs Outlier Removal</td>
<td>0.6328</td>
<td>0.9366</td>
<td>0.9509</td>
</tr>
</tbody>
</table>
</div>
<!-- default theme -->

<style>
  /* import google fonts */
  @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
  @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

  /* -------------------------------------------------- */
  /* global */
  /* -------------------------------------------------- */

  /* all elements */
  * {
    /* force sans-serif font unless specified otherwise */
    font-family: "Open Sans", "Helvetica", sans-serif;

    /* prevent text inflation on some mobile browsers */
    -webkit-text-size-adjust: none !important;
    -moz-text-size-adjust: none !important;
    -o-text-size-adjust: none !important;
    text-size-adjust: none !important;
  }

  @media only screen {
    /* "page" element */
    body {
      position: relative;
      box-sizing: border-box;
      font-size: 12pt;
      line-height: 1.5;
      max-width: 8.5in;
      margin: 20px auto;
      padding: 40px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* "page" element */
    body {
      padding: 20px;
      margin: 0;
      border-radius: 0;
      border: none;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
      background: none;
    }
  }

  /* -------------------------------------------------- */
  /* headings */
  /* -------------------------------------------------- */

  /* all headings */
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin: 20px 0;
    padding: 0;
    font-weight: bold;
  }

  /* biggest heading */
  h1 {
    margin: 40px 0;
    text-align: center;
  }

  /* second biggest heading */
  h2 {
    margin-top: 30px;
    padding-bottom: 5px;
    border-bottom: solid 1px #bdbdbd;
  }

  /* heading font sizes */
  h1 {
    font-size: 2em;
  }
  h2 {
    font-size: 1.5em;
  }
  h3 {
    font-size: 1.35em;
  }
  h4 {
    font-size: 1.25em;
  }
  h5 {
    font-size: 1.15em;
  }
  h6 {
    font-size: 1em;
  }

  /* -------------------------------------------------- */
  /* manuscript header */
  /* -------------------------------------------------- */

  /* manuscript title */
  header > h1 {
    margin: 0;
  }

  /* manuscript title caption text (ie "automatically generated on") */
  header + p {
    text-align: center;
    margin-top: 10px;
  }

  /* -------------------------------------------------- */
  /* text elements */
  /* -------------------------------------------------- */

  /* links */
  a {
    color: #2196f3;
    overflow-wrap: break-word;
  }

  /* superscripts and subscripts */
  sub,
  sup {
    /* prevent from affecting line height */
    line-height: 0;
  }

  /* unordered and ordered lists*/
  ul,
  ol {
    padding-left: 20px;
  }

  /* class for styling text semibold */
  .semibold {
    font-weight: 600;
  }

  /* class for styling elements horizontally left aligned */
  .left {
    display: block;
    text-align: left;
    margin-left: auto;
    margin-right: 0;
    justify-content: left;
  }

  /* class for styling elements horizontally centered */
  .center {
    display: block;
    text-align: center;
    margin-left: auto;
    margin-right: auto;
    justify-content: center;
  }

  /* class for styling elements horizontally right aligned */
  .right {
    display: block;
    text-align: right;
    margin-left: 0;
    margin-right: auto;
    justify-content: right;
  }

  /* -------------------------------------------------- */
  /* section elements */
  /* -------------------------------------------------- */

  /* horizontal divider line */
  hr {
    border: none;
    height: 1px;
    background: #bdbdbd;
  }

  /* paragraphs, horizontal dividers, figures, tables, code */
  p,
  hr,
  figure,
  table,
  pre {
    /* treat all as "paragraphs", with consistent vertical margins */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* figures */
  /* -------------------------------------------------- */

  /* figure */
  figure {
    max-width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure caption */
  figcaption {
    padding: 0;
    padding-top: 10px;
  }

  /* figure image element */
  figure > img,
  figure > svg {
    max-width: 100%;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure auto-number */
  img + figcaption > span:first-of-type,
  svg + figcaption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* tables */
  /* -------------------------------------------------- */

  /* table */
  table {
    border-collapse: collapse;
    border-spacing: 0;
    width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* table cells */
  th,
  td {
    border: solid 1px #bdbdbd;
    padding: 10px;
    /* squash table if too wide for page by forcing line breaks */
    overflow-wrap: break-word;
    word-break: break-word;
  }

  /* header row and even rows */
  th,
  tr:nth-child(2n) {
    background-color: #fafafa;
  }

  /* odd rows */
  tr:nth-child(2n + 1) {
    background-color: #ffffff;
  }

  /* table caption */
  caption {
    text-align: left;
    padding: 0;
    padding-bottom: 10px;
  }

  /* table auto-number */
  table > caption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* code */
  /* -------------------------------------------------- */

  /* multi-line code block */
  pre {
    padding: 10px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
    break-inside: avoid;
    text-align: left;
  }

  /* inline code, ie code within normal text */
  :not(pre) > code {
    padding: 0 4px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
  }

  /* code text */
  /* apply all children, to reach syntax highlighting sub-elements */
  code,
  code * {
    /* force monospace font */
    font-family: "Source Code Pro", "Courier New", monospace;
  }

  /* -------------------------------------------------- */
  /* quotes */
  /* -------------------------------------------------- */

  /* quoted text */
  blockquote {
    margin: 0;
    padding: 0;
    border-left: 4px solid #bdbdbd;
    padding-left: 16px;
    break-inside: avoid;
  }

  /* -------------------------------------------------- */
  /* banners */
  /* -------------------------------------------------- */

  /* info banners */
  .banner {
    box-sizing: border-box;
    display: block;
    position: relative;
    width: 100%;
    margin-top: 20px;
    margin-bottom: 20px;
    padding: 20px;
    text-align: center;
  }

  /* paragraph in banner */
  .banner > p {
    margin: 0;
  }

  /* -------------------------------------------------- */
  /* highlight colors */
  /* -------------------------------------------------- */

  .white {
    background: #ffffff;
  }
  .lightgrey {
    background: #eeeeee;
  }
  .grey {
    background: #757575;
  }
  .darkgrey {
    background: #424242;
  }
  .black {
    background: #000000;
  }
  .lightred {
    background: #ffcdd2;
  }
  .lightyellow {
    background: #ffecb3;
  }
  .lightgreen {
    background: #dcedc8;
  }
  .lightblue {
    background: #e3f2fd;
  }
  .lightpurple {
    background: #f3e5f5;
  }
  .red {
    background: #f44336;
  }
  .orange {
    background: #ff9800;
  }
  .yellow {
    background: #ffeb3b;
  }
  .green {
    background: #4caf50;
  }
  .blue {
    background: #2196f3;
  }
  .purple {
    background: #9c27b0;
  }
  .white,
  .lightgrey,
  .lightred,
  .lightyellow,
  .lightgreen,
  .lightblue,
  .lightpurple,
  .orange,
  .yellow,
  .white a,
  .lightgrey a,
  .lightred a,
  .lightyellow a,
  .lightgreen a,
  .lightblue a,
  .lightpurple a,
  .orange a,
  .yellow a {
    color: #000000;
  }
  .grey,
  .darkgrey,
  .black,
  .red,
  .green,
  .blue,
  .purple,
  .grey a,
  .darkgrey a,
  .black a,
  .red a,
  .green a,
  .blue a,
  .purple a {
    color: #ffffff;
  }

  /* -------------------------------------------------- */
  /* buttons */
  /* -------------------------------------------------- */

  /* class for styling links like buttons */
  .button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    margin: 5px;
    padding: 10px 20px;
    font-size: 0.75em;
    font-weight: 600;
    text-transform: uppercase;
    text-decoration: none;
    letter-spacing: 1px;
    background: none;
    color: #2196f3;
    border: solid 1px #bdbdbd;
    border-radius: 5px;
  }

  /* buttons when hovered */
  .button:hover:not([disabled]),
  .icon_button:hover:not([disabled]) {
    cursor: pointer;
    background: #f5f5f5;
  }

  /* buttons when disabled */
  .button[disabled],
  .icon_button[disabled] {
    opacity: 0.35;
    pointer-events: none;
  }

  /* class for styling buttons containg only single icon */
  .icon_button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    text-decoration: none;
    margin: 0;
    padding: 0;
    background: none;
    border-radius: 5px;
    border: none;
    width: 20px;
    height: 20px;
    min-width: 20px;
    min-height: 20px;
  }

  /* icon button inner svg image */
  .icon_button > svg {
    height: 16px;
  }

  /* -------------------------------------------------- */
  /* icons */
  /* -------------------------------------------------- */

  /* class for styling icons inline with text */
  .inline_icon {
    height: 1em;
    position: relative;
    top: 0.125em;
  }

  /* -------------------------------------------------- */
  /* references */
  /* -------------------------------------------------- */

  .csl-entry {
    margin-top: 15px;
    margin-bottom: 15px;
  }

  /* -------------------------------------------------- */
  /* print control */
  /* -------------------------------------------------- */

  @media print {
    @page {
      /* suggested printing margin */
      margin: 0.5in;
    }

    /* document and "page" elements */
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }

    /* "page" element */
    body {
      font-size: 11pt !important;
      line-height: 1.35;
    }

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      margin: 15px 0;
    }

    /* figures and tables */
    figure,
    table {
      font-size: 0.85em;
    }

    /* table cells */
    th,
    td {
      padding: 5px;
    }

    /* shrink font awesome icons */
    i.fas,
    i.fab,
    i.far,
    i.fal {
      transform: scale(0.85);
    }

    /* decrease banner margins */
    .banner {
      margin-top: 15px;
      margin-bottom: 15px;
      padding: 15px;
    }

    /* class for centering an element vertically on its own page */
    .page_center {
      margin: auto;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      vertical-align: middle;
      break-before: page;
      break-after: page;
    }

    /* always insert a page break before the element */
    .page_break_before {
      break-before: page;
    }

    /* always insert a page break after the element */
    .page_break_after {
      break-after: page;
    }

    /* avoid page break before the element */
    .page_break_before_avoid {
      break-before: avoid;
    }

    /* avoid page break after the element */
    .page_break_after_avoid {
      break-after: avoid;
    }

    /* avoid page break inside the element */
    .page_break_inside_avoid {
      break-inside: avoid;
    }
  }

  /* -------------------------------------------------- */
  /* override pandoc css quirks */
  /* -------------------------------------------------- */

  .sourceCode {
    /* prevent unsightly overflow in wide code blocks */
    overflow: auto !important;
  }

  div.sourceCode {
    /* prevent background fill on top-most code block  container */
    background: none !important;
  }

  .sourceCode * {
    /* force consistent line spacing */
    line-height: 1.5 !important;
  }

  div.sourceCode {
    /* style code block margins same as <pre> element */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* tablenos */
  /* -------------------------------------------------- */

  /* tablenos wrapper */
  .tablenos {
    width: 100%;
    margin: 20px 0;
  }

  .tablenos > table {
    /* move margins from table to table_wrapper to allow margin collapsing */
    margin: 0;
  }

  @media only screen {
    /* tablenos wrapper */
    .tablenos {
      /* show scrollbar on tables if necessary to prevent overflow */
      overflow-x: auto !important;
    }

    .tablenos th,
    .tablenos td {
      overflow-wrap: unset !important;
      word-break: unset !important;
    }

    /* table in wrapper */
    .tablenos table,
    .tablenos table * {
      /* don't break table words */
      overflow-wrap: normal !important;
    }
  }
</style>
<!-- 
    Plugin Core

    Functions needed for and shared across all first-party plugins.
-->

<script>
  // get element that is target of hash (from link element or url)
  function getHashTarget(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector(`[id="${id}"]`);
    if (!target) return;

    // if figure or table, modify target to get expected element
    if (id.indexOf("fig:") === 0) target = target.querySelector("figure");
    if (id.indexOf("tbl:") === 0) target = target.querySelector("table");

    return target;
  }

  // get position/dimensions of element or viewport
  function getRectInView(element) {
    let rect = {};
    rect.left = 0;
    rect.top = 0;
    rect.right = document.documentElement.clientWidth;
    rect.bottom = document.documentElement.clientHeight;
    let style = {};

    if (element instanceof HTMLElement) {
      rect = element.getBoundingClientRect();
      style = window.getComputedStyle(element);
    }

    const margin = {};
    margin.left = parseFloat(style.marginLeftWidth) || 0;
    margin.top = parseFloat(style.marginTopWidth) || 0;
    margin.right = parseFloat(style.marginRightWidth) || 0;
    margin.bottom = parseFloat(style.marginBottomWidth) || 0;

    const border = {};
    border.left = parseFloat(style.borderLeftWidth) || 0;
    border.top = parseFloat(style.borderTopWidth) || 0;
    border.right = parseFloat(style.borderRightWidth) || 0;
    border.bottom = parseFloat(style.borderBottomWidth) || 0;

    const newRect = {};
    newRect.left = rect.left + margin.left + border.left;
    newRect.top = rect.top + margin.top + border.top;
    newRect.right = rect.right + margin.right + border.right;
    newRect.bottom = rect.bottom + margin.bottom + border.bottom;
    newRect.width = newRect.right - newRect.left;
    newRect.height = newRect.bottom - newRect.top;

    return newRect;
  }

  // get position of element relative to page
  function getRectInPage(element) {
    const rect = getRectInView(element);
    const body = getRectInView(document.body);

    const newRect = {};
    newRect.left = rect.left - body.left;
    newRect.top = rect.top - body.top;
    newRect.right = rect.right - body.left;
    newRect.bottom = rect.bottom - body.top;
    newRect.width = rect.width;
    newRect.height = rect.height;

    return newRect;
  }

  // get closest element before specified element that matches query
  function firstBefore(element, query) {
    while (element && element !== document.body && !element.matches(query))
      element = element.previousElementSibling || element.parentNode;

    return element;
  }

  // check if element is part of collapsed heading
  function isCollapsed(element) {
    while (element && element !== document.body) {
      if (element.dataset.collapsed === "true") return true;
      element = element.parentNode;
    }
    return false;
  }

  // expand any collapsed parent containers of element if necessary
  function expandElement(element) {
    if (isCollapsed(element)) {
      // accordion plugin
      const heading = firstBefore(element, "h2");
      if (heading) heading.click();
      // details/summary HTML element
      const summary = firstBefore(element, "summary");
      if (summary) summary.click();
    }
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);

    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // get list of elements after a start element up to element matching query
  function nextUntil(element, query, exclude) {
    const elements = [];
    while (((element = element.nextElementSibling), element)) {
      if (element.matches(query)) break;
      if (!element.matches(exclude)) elements.push(element);
    }
    return elements;
  }
</script>
<!--
  Accordion Plugin

  Allows sections of content under h2 headings to be collapsible.
-->

<script type="module">
  // whether to always start expanded ('false'), always start collapsed
  // ('true'), or start collapsed when screen small ('auto')
  const startCollapsed = "auto";

  // start script
  function start() {
    // run through each <h2> heading
    const headings = document.querySelectorAll("h2");
    for (const heading of headings) {
      addArrow(heading);

      // start expanded/collapsed based on option
      if (
        startCollapsed === "true" ||
        (startCollapsed === "auto" && isSmallScreen()) ||
        heading.dataset.collapsed === "true"
      )
        collapseHeading(heading);
      else expandElement(heading);
    }

    // attach hash change listener to window
    window.addEventListener("hashchange", onHashChange);
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) goToElement(target);
  }

  // add arrow to heading
  function addArrow(heading) {
    // add arrow button
    const arrow = document.createElement("button");
    arrow.innerHTML = document.querySelector(".icon_angle_down").innerHTML;
    arrow.classList.add("icon_button", "accordion_arrow");
    heading.insertBefore(arrow, heading.firstChild);

    // attach click listener to heading and button
    heading.addEventListener("click", onHeadingClick);
    arrow.addEventListener("click", onArrowClick);
  }

  // determine if on mobile-like device with small screen
  function isSmallScreen() {
    return Math.min(window.innerWidth, window.innerHeight) < 480;
  }

  // when <h2> heading is clicked
  function onHeadingClick(event) {
    // only collapse if <h2> itself is target of click (eg, user did
    // not click on anchor within <h2>)
    if (event.target === this) toggleCollapse(this);
  }

  // when arrow button is clicked
  function onArrowClick() {
    toggleCollapse(this.parentNode);
  }

  // collapse section if expanded, expand if collapsed
  function toggleCollapse(heading) {
    if (heading.dataset.collapsed === "false") collapseHeading(heading);
    else expandElement(heading);
  }

  // elements to exclude from collapse, such as table of contents panel,
  // hypothesis panel, etc
  const exclude = "#toc_panel, div.annotator-frame, #lightbox_overlay";

  // collapse section
  function collapseHeading(heading) {
    heading.setAttribute("data-collapsed", "true");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "true");
  }

  // expand section
  function expandElement(heading) {
    heading.setAttribute("data-collapsed", "false");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "false");
  }

  // get list of elements between this <h2> and next <h2> or <h1>
  // ("children" of the <h2> section)
  function getChildren(heading) {
    return nextUntil(heading, "h2, h1", exclude);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
  <!-- modified from: https://fontawesome.com/icons/angle-down -->
  <svg width="16" height="16" viewBox="0 0 448 512">
    <path
      fill="currentColor"
      d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* accordion arrow button */
    .accordion_arrow {
      margin-right: 10px;
    }

    /* arrow icon when <h2> data-collapsed attribute true */
    h2[data-collapsed="true"] > .accordion_arrow > svg {
      transform: rotate(-90deg);
    }

    /* all elements (except <h2>'s) when data-collapsed attribute true */
    *:not(h2)[data-collapsed="true"] {
      display: none;
    }

    /* accordion arrow button when hovered and <h2>'s when hovered */
    .accordion_arrow:hover,
    h2[data-collapsed="true"]:hover,
    h2[data-collapsed="false"]:hover {
      cursor: pointer;
    }
  }

  /* always hide accordion arrow button on print */
  @media only print {
    .accordion_arrow {
      display: none;
    }
  }
</style>
<!--
  Anchors Plugin

  Adds an anchor next to each of a certain type of element that provides a
  human-readable url to that specific item/position in the document (e.g.
  "manuscript.html#abstract"). It also makes it such that scrolling out of view
  of a target removes its identifier from the url.
-->

<script type="module">
  // which types of elements to add anchors next to, in "document.querySelector"
  // format
  const typesQuery =
    'h1, h2, h3, div[id^="fig:"], div[id^="tbl:"], span[id^="eq:"]';

  // start script
  function start() {
    // add anchor to each element of specified types
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) addAnchor(element);

    // attach scroll listener to window
    window.addEventListener("scroll", onScroll);
  }

  // when window is scrolled
  function onScroll() {
    // if url has hash and user has scrolled out of view of hash
    // target, remove hash from url
    const tolerance = 100;
    const target = getHashTarget();
    if (target) {
      if (
        target.getBoundingClientRect().top > window.innerHeight + tolerance ||
        target.getBoundingClientRect().bottom < 0 - tolerance
      )
        history.pushState(null, null, " ");
    }
  }

  // add anchor to element
  function addAnchor(element) {
    let addTo; // element to add anchor button to

    // if figure or table, modify withId and addTo to get expected
    // elements
    if (element.id.indexOf("fig:") === 0) {
      addTo = element.querySelector("figcaption");
    } else if (element.id.indexOf("tbl:") === 0) {
      addTo = element.querySelector("caption");
    } else if (element.id.indexOf("eq:") === 0) {
      addTo = element.querySelector(".eqnos-number");
    }

    addTo = addTo || element;
    const id = element.id || null;

    // do not add anchor if element doesn't have assigned id.
    // id is generated by pandoc and is assumed to be unique and
    // human-readable
    if (!id) return;

    // create anchor button
    const anchor = document.createElement("a");
    anchor.innerHTML = document.querySelector(".icon_link").innerHTML;
    anchor.title = "Link to this part of the document";
    anchor.classList.add("icon_button", "anchor");
    anchor.dataset.ignore = "true";
    anchor.href = "#" + id;
    addTo.appendChild(anchor);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- link icon -->

<template class="icon_link">
  <!-- modified from: https://fontawesome.com/icons/link -->
  <svg width="16" height="16" viewBox="0 0 512 512">
    <path
      fill="currentColor"
      d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* anchor button */
    .anchor {
      opacity: 0;
      margin-left: 5px;
    }

    /* anchor buttons within <h2>'s */
    h2 .anchor {
      margin-left: 10px;
    }

    /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
    *:hover > .anchor,
    .anchor:hover,
    .anchor:focus {
      opacity: 1;
    }

    /* anchor button when hovered */
    .anchor:hover {
      cursor: pointer;
    }
  }

  /* always show anchor button on devices with no mouse/hover ability */
  @media (hover: none) {
    .anchor {
      opacity: 1;
    }
  }

  /* always hide anchor button on print */
  @media only print {
    .anchor {
      display: none;
    }
  }
</style>
<!-- 
    Attributes Plugin

    Allows arbitrary HTML attributes to be attached to (almost) any element.
    Place an HTML comment inside or next to the desired element with the content:
    $attribute="value"
-->

<script type="module">
  // start script
  function start() {
    // get list of comments in document
    const comments = findComments();

    for (const comment of comments)
      if (comment.parentElement)
        addAttributes(comment.parentElement, comment.nodeValue.trim());
  }

  // add html attributes to specified element based on string of
  // html attributes and values
  function addAttributes(element, text) {
    // regex's for finding attribute/value pairs in the format of
    // attribute="value" or attribute='value
    const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
    const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

    // loop through attribute/value pairs
    let match;
    while ((match = text.match(regex2) || text.match(regex1))) {
      // get attribute and value from regex capture groups
      let attribute = match[1];
      let value = match[2];

      // remove from string
      text = text.substring(match.index + match[0].length);

      if (!attribute || !value) break;

      // set attribute of parent element
      try {
        element.setAttribute(attribute, value);
      } catch (error) {
        console.log(error);
      }

      // special case for colspan
      if (attribute === "colspan") removeTableCells(element, value);
    }
  }

  // get list of comment elements in document
  function findComments() {
    const comments = [];

    // iterate over comment nodes in document
    function acceptNode(node) {
      return NodeFilter.FILTER_ACCEPT;
    }
    const iterator = document.createNodeIterator(
      document.body,
      NodeFilter.SHOW_COMMENT,
      acceptNode
    );
    let node;
    while ((node = iterator.nextNode())) comments.push(node);

    return comments;
  }

  // remove certain number of cells after specified cell
  function removeTableCells(cell, number) {
    number = parseInt(number);
    if (!number) return;

    // remove elements
    for (; number > 1; number--) {
      if (cell.nextElementSibling) cell.nextElementSibling.remove();
    }
  }

  // start script on DOMContentLoaded instead of load to ensure this plugins
  // runs before other plugins
  window.addEventListener("DOMContentLoaded", start);
</script>
<!--
  Jump to First Plugin

  Adds a button next to each reference entry, figure, and table that jumps the
  page to the first occurrence of a link to that item in the manuscript.
-->

<script type="module">
  // whether to add buttons next to reference entries
  const references = "true";
  // whether to add buttons next to figures
  const figures = "true";
  // whether to add buttons next to tables
  const tables = "true";

  // start script
  function start() {
    if (references !== "false")
      makeButtons(`div[id^="ref-"]`, ".csl-left-margin", "reference");
    if (figures !== "false")
      makeButtons(`div[id^="fig:"]`, "figcaption", "figure");
    if (tables !== "false") makeButtons(`div[id^="tbl:"]`, "caption", "table");
  }

  // when jump button clicked
  function onButtonClick() {
    const first = getFirstOccurrence(this.dataset.id);
    if (!first) return;

    // update url hash so navigating "back" in history will return user to button
    window.location.hash = this.dataset.id;
    // scroll to link
    const timeout = function () {
      goToElement(first, window.innerHeight * 0.5);
    };
    window.setTimeout(timeout, 0);
  }

  // get first occurrence of link to item in document
  function getFirstOccurrence(id) {
    let query = "a";
    query += '[href="#' + id + '"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelector(query);
  }

  // add button next to each reference entry, figure, or table
  function makeButtons(query, containerQuery, subject) {
    const elements = document.querySelectorAll(query);
    for (const element of elements) {
      const id = element.id;
      const buttonContainer = element.querySelector(containerQuery);
      const first = getFirstOccurrence(id);

      // if can't find link to reference or place to put button, ignore
      if (!first || !buttonContainer) continue;

      // make jump button
      let button = document.createElement("button");
      button.classList.add("icon_button", "jump_arrow");
      button.title = `Jump to the first occurrence of this ${subject} in the document`;
      const icon = document.querySelector(".icon_angle_double_up");
      button.innerHTML = icon.innerHTML;
      button.dataset.id = id;
      button.dataset.ignore = "true";
      button.addEventListener("click", onButtonClick);
      buttonContainer.prepend(button);
    }
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
  <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
  <svg width="16" height="16" viewBox="0 0 320 512">
    <path
      fill="currentColor"
      d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* jump button */
    .jump_arrow {
      position: relative;
      top: 0.125em;
      margin-right: 5px;
    }
  }

  /* always hide jump button on print */
  @media only print {
    .jump_arrow {
      display: none;
    }
  }
</style>
<!-- 
    Lightbox Plugin

    Makes it such that when a user clicks on an image, the image fills the
    screen and the user can pan/drag/zoom the image and navigate between other
    images in the document.
-->

<script type="module">
  // list of possible zoom/scale factors
  const zooms =
    "0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8";
  // whether to fit image to view ('fit'), display at 100% and shrink if
  // necessary ('shrink'), or always display at 100% ('100')
  const defaultZoom = "fit";
  // whether to zoom in/out toward center of view ('true') or mouse ('false')
  const centerZoom = "false";

  // start script
  function start() {
    // run through each <img> element
    const imgs = document.querySelectorAll("figure > img");
    let count = 1;
    for (const img of imgs) {
      img.classList.add("lightbox_document_img");
      img.dataset.number = count;
      img.dataset.total = imgs.length;
      img.addEventListener("click", openLightbox);
      count++;
    }

    // attach mouse and key listeners to window
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("keyup", onKeyUp);
  }

  // when mouse is moved anywhere in window
  function onWindowMouseMove(event) {
    window.mouseX = event.clientX;
    window.mouseY = event.clientY;
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("lightbox_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("lightbox_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeLightbox();
        break;
    }
  }

  // open lightbox
  function openLightbox() {
    const lightbox = makeLightbox(this);
    if (!lightbox) return;

    blurBody(lightbox);
    document.body.appendChild(lightbox);
  }

  // make lightbox
  function makeLightbox(img) {
    // delete lightbox if it exists, start fresh
    closeLightbox();

    // create screen overlay containing lightbox
    const overlay = document.createElement("div");
    overlay.id = "lightbox_overlay";

    // create image info boxes
    const numberInfo = document.createElement("div");
    const zoomInfo = document.createElement("div");
    numberInfo.id = "lightbox_number_info";
    zoomInfo.id = "lightbox_zoom_info";

    // create container for image
    const imageContainer = document.createElement("div");
    imageContainer.id = "lightbox_image_container";
    const lightboxImg = makeLightboxImg(
      img,
      imageContainer,
      numberInfo,
      zoomInfo
    );
    imageContainer.appendChild(lightboxImg);

    // create bottom container for caption and navigation buttons
    const bottomContainer = document.createElement("div");
    bottomContainer.id = "lightbox_bottom_container";
    const caption = makeCaption(img);
    const prevButton = makePrevButton(img);
    const nextButton = makeNextButton(img);
    bottomContainer.appendChild(prevButton);
    bottomContainer.appendChild(caption);
    bottomContainer.appendChild(nextButton);

    // attach top middle and bottom to overlay
    overlay.appendChild(numberInfo);
    overlay.appendChild(zoomInfo);
    overlay.appendChild(imageContainer);
    overlay.appendChild(bottomContainer);

    return overlay;
  }

  // make <img> object that is intuitively draggable and zoomable
  function makeLightboxImg(sourceImg, container, numberInfoBox, zoomInfoBox) {
    // create copy of source <img>
    const img = sourceImg.cloneNode(true);
    img.classList.remove("lightbox_document_img");
    img.removeAttribute("id");
    img.removeAttribute("width");
    img.removeAttribute("height");
    img.style.position = "unset";
    img.style.margin = "0";
    img.style.padding = "0";
    img.style.width = "";
    img.style.height = "";
    img.style.minWidth = "";
    img.style.minHeight = "";
    img.style.maxWidth = "";
    img.style.maxHeight = "";
    img.id = "lightbox_img";

    // build sorted list of zoomSteps
    const zoomSteps = zooms.split(/[^0-9.]/).map((step) => parseFloat(step));
    zoomSteps.sort((a, b) => a - b);

    // <img> object property variables
    let zoom = 1;
    let translateX = 0;
    let translateY = 0;
    let clickMouseX = undefined;
    let clickMouseY = undefined;
    let clickTranslateX = undefined;
    let clickTranslateY = undefined;

    updateNumberInfo();

    // update image numbers displayed in info box
    function updateNumberInfo() {
      numberInfoBox.innerHTML =
        sourceImg.dataset.number + " of " + sourceImg.dataset.total;
    }

    // update zoom displayed in info box
    function updateZoomInfo() {
      let zoomInfo = zoom * 100;
      if (!Number.isInteger(zoomInfo)) zoomInfo = zoomInfo.toFixed(2);
      zoomInfoBox.innerHTML = zoomInfo + "%";
    }

    // move to closest zoom step above current zoom
    const zoomIn = function () {
      for (const zoomStep of zoomSteps) {
        if (zoomStep > zoom) {
          zoom = zoomStep;
          break;
        }
      }
      updateTransform();
    };

    // move to closest zoom step above current zoom
    const zoomOut = function () {
      zoomSteps.reverse();
      for (const zoomStep of zoomSteps) {
        if (zoomStep < zoom) {
          zoom = zoomStep;
          break;
        }
      }
      zoomSteps.reverse();

      updateTransform();
    };

    // update display of <img> based on scale/translate properties
    const updateTransform = function () {
      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      // get new width/height after scale
      const rect = img.getBoundingClientRect();
      // limit translate
      translateX = Math.max(translateX, -rect.width / 2);
      translateX = Math.min(translateX, rect.width / 2);
      translateY = Math.max(translateY, -rect.height / 2);
      translateY = Math.min(translateY, rect.height / 2);

      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      updateZoomInfo();
    };

    // fit <img> to container
    const fit = function () {
      // no x/y offset, 100% zoom by default
      translateX = 0;
      translateY = 0;
      zoom = 1;

      // widths of <img> and container
      const imgWidth = img.naturalWidth;
      const imgHeight = img.naturalHeight;
      const containerWidth = parseFloat(
        window.getComputedStyle(container).width
      );
      const containerHeight = parseFloat(
        window.getComputedStyle(container).height
      );

      // how much zooming is needed to fit <img> to container
      const xRatio = imgWidth / containerWidth;
      const yRatio = imgHeight / containerHeight;
      const maxRatio = Math.max(xRatio, yRatio);
      const newZoom = 1 / maxRatio;

      // fit <img> to container according to option
      if (defaultZoom === "shrink") {
        if (maxRatio > 1) zoom = newZoom;
      } else if (defaultZoom === "fit") zoom = newZoom;

      updateTransform();
    };

    // when mouse wheel is rolled anywhere in container
    const onContainerWheel = function (event) {
      if (!event) return;

      // let ctrl + mouse wheel to zoom behave as normal
      if (event.ctrlKey) return;

      // prevent normal scroll behavior
      event.preventDefault();
      event.stopPropagation();

      // point around which to scale img
      const viewRect = container.getBoundingClientRect();
      const viewX = (viewRect.left + viewRect.right) / 2;
      const viewY = (viewRect.top + viewRect.bottom) / 2;
      const originX = centerZoom === "true" ? viewX : mouseX;
      const originY = centerZoom === "true" ? viewY : mouseY;

      // get point on image under origin
      const oldRect = img.getBoundingClientRect();
      const oldPercentX = (originX - oldRect.left) / oldRect.width;
      const oldPercentY = (originY - oldRect.top) / oldRect.height;

      // increment/decrement zoom
      if (event.deltaY < 0) zoomIn();
      if (event.deltaY > 0) zoomOut();

      // get offset between previous image point and origin
      const newRect = img.getBoundingClientRect();
      const offsetX = originX - (newRect.left + newRect.width * oldPercentX);
      const offsetY = originY - (newRect.top + newRect.height * oldPercentY);

      // translate image to keep image point under origin
      translateX += offsetX;
      translateY += offsetY;

      // perform translate
      updateTransform();
    };

    // when container is clicked
    function onContainerClick(event) {
      // if container itself is target of click, and not other
      // element above it
      if (event.target === this) closeLightbox();
    }

    // when mouse button is pressed on image
    const onImageMouseDown = function (event) {
      // store original mouse position relative to image
      clickMouseX = window.mouseX;
      clickMouseY = window.mouseY;
      clickTranslateX = translateX;
      clickTranslateY = translateY;
      event.stopPropagation();
      event.preventDefault();
    };

    // when mouse button is released anywhere in window
    const onWindowMouseUp = function (event) {
      // reset original mouse position
      clickMouseX = undefined;
      clickMouseY = undefined;
      clickTranslateX = undefined;
      clickTranslateY = undefined;

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mouseup", onWindowMouseUp);
    };

    // when mouse is moved anywhere in window
    const onWindowMouseMove = function (event) {
      if (
        clickMouseX === undefined ||
        clickMouseY === undefined ||
        clickTranslateX === undefined ||
        clickTranslateY === undefined
      )
        return;

      // offset image based on original and current mouse position
      translateX = clickTranslateX + window.mouseX - clickMouseX;
      translateY = clickTranslateY + window.mouseY - clickMouseY;
      updateTransform();
      event.preventDefault();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mousemove", onWindowMouseMove);
    };

    // when window is resized
    const onWindowResize = function (event) {
      fit();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("resize", onWindowResize);
    };

    // attach the necessary event listeners
    img.addEventListener("dblclick", fit);
    img.addEventListener("mousedown", onImageMouseDown);
    container.addEventListener("wheel", onContainerWheel);
    container.addEventListener("mousedown", onContainerClick);
    container.addEventListener("touchstart", onContainerClick);
    window.addEventListener("mouseup", onWindowMouseUp);
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("resize", onWindowResize);

    // run fit() after lightbox atttached to document and <img> Loaded
    // so needed container and img dimensions available
    img.addEventListener("load", fit);

    return img;
  }

  // make caption
  function makeCaption(img) {
    const caption = document.createElement("div");
    caption.id = "lightbox_caption";
    const captionSource = img.nextElementSibling;
    if (captionSource.tagName.toLowerCase() === "figcaption") {
      const captionCopy = makeCopy(captionSource);
      caption.innerHTML = captionCopy.innerHTML;
    }

    caption.addEventListener("touchstart", function (event) {
      event.stopPropagation();
    });

    return caption;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // make button to jump to previous image in document
  function makePrevButton(img) {
    const prevButton = document.createElement("button");
    prevButton.id = "lightbox_prev_button";
    prevButton.title = "Jump to the previous image in the document [←]";
    prevButton.classList.add("icon_button", "lightbox_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;

    // attach click listeners to button
    prevButton.addEventListener("click", function () {
      getPrevImg(img).click();
    });

    return prevButton;
  }

  // make button to jump to next image in document
  function makeNextButton(img) {
    const nextButton = document.createElement("button");
    nextButton.id = "lightbox_next_button";
    nextButton.title = "Jump to the next image in the document [→]";
    nextButton.classList.add("icon_button", "lightbox_button");
    nextButton.innerHTML = document.querySelector(
      ".icon_caret_right"
    ).innerHTML;

    // attach click listeners to button
    nextButton.addEventListener("click", function () {
      getNextImg(img).click();
    });

    return nextButton;
  }

  // get previous image in document
  function getPrevImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if < 1
    if (index - 1 >= 0) index--;
    else index = imgs.length - 1;
    return imgs[index];
  }

  // get next image in document
  function getNextImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if > total
    if (index + 1 <= imgs.length - 1) index++;
    else index = 0;
    return imgs[index];
  }

  // close lightbox
  function closeLightbox() {
    focusBody();

    const lightbox = document.getElementById("lightbox_overlay");
    if (lightbox) lightbox.remove();
  }

  // make all elements behind lightbox non-focusable
  function blurBody(overlay) {
    const all = document.querySelectorAll("*");
    for (const element of all) element.tabIndex = -1;
    document.body.classList.add("body_no_scroll");
  }

  // make all elements focusable again
  function focusBody() {
    const all = document.querySelectorAll("*");
    for (const element of all) element.removeAttribute("tabIndex");
    document.body.classList.remove("body_no_scroll");
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* regular <img> in document when hovered */
    img.lightbox_document_img:hover {
      cursor: pointer;
    }

    .body_no_scroll {
      overflow: hidden !important;
    }

    /* screen overlay */
    #lightbox_overlay {
      display: flex;
      flex-direction: column;
      position: fixed;
      left: 0;
      top: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.75);
      z-index: 3;
    }

    /* middle area containing lightbox image */
    #lightbox_image_container {
      flex-grow: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
      position: relative;
      padding: 20px;
    }

    /* bottom area containing caption */
    #lightbox_bottom_container {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100px;
      min-height: 100px;
      max-height: 100px;
      background: rgba(0, 0, 0, 0.5);
    }

    /* image number info text box */
    #lightbox_number_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      left: 2px;
      top: 0;
      z-index: 4;
    }

    /* zoom info text box */
    #lightbox_zoom_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      right: 2px;
      top: 0;
      z-index: 4;
    }

    /* copy of image caption */
    #lightbox_caption {
      box-sizing: border-box;
      display: inline-block;
      width: 100%;
      max-height: 100%;
      padding: 10px 0;
      text-align: center;
      overflow-y: auto;
      color: #ffffff;
    }

    /* navigation previous/next button */
    .lightbox_button {
      width: 100px;
      height: 100%;
      min-width: 100px;
      min-height: 100%;
      color: #ffffff;
    }

    /* navigation previous/next button when hovered */
    .lightbox_button:hover {
      background: none !important;
    }

    /* navigation button icon */
    .lightbox_button > svg {
      height: 25px;
    }

    /* figure auto-number */
    #lightbox_caption > span:first-of-type {
      font-weight: bold;
      margin-right: 5px;
    }

    /* lightbox image when hovered */
    #lightbox_img:hover {
      cursor: grab;
    }

    /* lightbox image when grabbed */
    #lightbox_img:active {
      cursor: grabbing;
    }
  }

  /* when on screen < 480px wide */
  @media only screen and (max-width: 480px) {
    /* make navigation buttons skinnier on small screens to make more room for caption text */
    .lightbox_button {
      width: 50px;
      min-width: 50px;
    }
  }

  /* always hide lightbox on print */
  @media only print {
    #lightbox_overlay {
      display: none;
    }
  }
</style>
<!-- 
  Link Highlight Plugin

  Makes it such that when a user hovers or focuses a link, other links that have
  the same target will be highlighted. It also makes it such that when clicking
  a link, the target of the link (eg reference, figure, table) is briefly
  highlighted.
-->

<script type="module">
  // whether to also highlight links that go to external urls
  const externalLinks = "false";
  // whether user must click off to unhighlight instead of just
  // un-hovering
  const clickUnhighlight = "false";
  // whether to also highlight links that are unique
  const highlightUnique = "true";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach mouse and focus listeners to link
      link.addEventListener("mouseenter", onLinkFocus);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("mouseleave", onLinkUnhover);
    }

    // attach click and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("hashchange", onHashChange);

    // run hash change on window load in case user has navigated
    // directly to hash
    onHashChange();
  }

  // when link is focused (tabbed to) or hovered
  function onLinkFocus() {
    highlight(this);
  }

  // when link is unhovered
  function onLinkUnhover() {
    if (clickUnhighlight !== "true") unhighlightAll();
  }

  // when the mouse is clicked anywhere in window
  function onClick(event) {
    unhighlightAll();
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) glowElement(target);
  }

  // start glow sequence on an element
  function glowElement(element) {
    const startGlow = function () {
      onGlowEnd();
      element.dataset.glow = "true";
      element.addEventListener("animationend", onGlowEnd);
    };
    const onGlowEnd = function () {
      element.removeAttribute("data-glow");
      element.removeEventListener("animationend", onGlowEnd);
    };
    startGlow();
  }

  // highlight link and all others with same target
  function highlight(link) {
    // force unhighlight all to start fresh
    unhighlightAll();

    // get links with same target
    if (!link) return;
    const sameLinks = getSameLinks(link);

    // if link unique and option is off, exit and don't highlight
    if (sameLinks.length <= 1 && highlightUnique !== "true") return;

    // highlight all same links, and "select" (special highlight) this
    // one
    for (const sameLink of sameLinks) {
      if (sameLink === link) sameLink.setAttribute("data-selected", "true");
      else sameLink.setAttribute("data-highlighted", "true");
    }
  }

  // unhighlight all links
  function unhighlightAll() {
    const links = getLinks();
    for (const link of links) {
      link.setAttribute("data-selected", "false");
      link.setAttribute("data-highlighted", "false");
    }
  }

  // get links with same target
  function getSameLinks(link) {
    const results = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        results.push(otherLink);
    }
    return results;
  }

  // get all links of types we wish to handle
  function getLinks() {
    let query = "a";
    if (externalLinks !== "true") query += '[href^="#"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelectorAll(query);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<style>
  @media only screen {
    /* anything with data-highlighted attribute true */
    [data-highlighted="true"] {
      background: #ffeb3b;
    }

    /* anything with data-selected attribute true */
    [data-selected="true"] {
      background: #ff8a65 !important;
    }

    /* animation definition for glow */
    @keyframes highlight_glow {
      0% {
        background: none;
      }
      10% {
        background: #bbdefb;
      }
      100% {
        background: none;
      }
    }

    /* anything with data-glow attribute true */
    [data-glow="true"] {
      animation: highlight_glow 2s;
    }
  }
</style>
<!--
  Table of Contents Plugin

  Provides a "table of contents" (toc) panel on the side of the document that
  allows the user to conveniently navigate between sections of the document.
-->

<script type="module">
  // which types of elements to add links for, in "document.querySelector" format
  const typesQuery = "h1, h2, h3";
  // whether toc starts open. use 'true' or 'false', or 'auto' to
  // use 'true' behavior when screen wide enough and 'false' when not
  const startOpen = "false";
  // whether toc closes when clicking on toc link. use 'true' or
  // 'false', or 'auto' to use 'false' behavior when screen wide
  // enough and 'true' when not
  const clickClose = "auto";
  // if list item is more than this many characters, text will be
  // truncated
  const charLimit = "50";
  // whether or not to show bullets next to each toc item
  const bullets = "false";

  // start script
  function start() {
    // make toc panel and populate with entries (links to document
    // sections)
    const panel = makePanel();
    if (!panel) return;
    makeEntries(panel);
    // attach panel to document after making entries, so 'toc' heading
    // in panel isn't included in toc
    document.body.insertBefore(panel, document.body.firstChild);

    // initial panel state
    if (startOpen === "true" || (startOpen === "auto" && !isSmallScreen()))
      openPanel();
    else closePanel();

    // attach click, scroll, and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("scroll", onScroll);
    window.addEventListener("hashchange", onScroll);
    window.addEventListener("keyup", onKeyUp);
    onScroll();

    // add class to push document body down out of way of toc button
    document.body.classList.add("toc_body_nudge");
  }

  // determine if screen wide enough to fit toc panel
  function isSmallScreen() {
    // in default theme:
    // 816px = 8.5in = width of "page" (<body>) element
    // 260px = min width of toc panel (*2 for both sides of <body>)
    return window.innerWidth < 816 + 260 * 2;
  }

  // when mouse is clicked anywhere in window
  function onClick() {
    if (isSmallScreen()) closePanel();
  }

  // when window is scrolled or hash changed
  function onScroll() {
    highlightViewed();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    // close on esc
    if (event.key === "Escape") closePanel();
  }

  // find entry of currently viewed document section in toc and highlight
  function highlightViewed() {
    const firstId = getFirstInView(typesQuery);

    // get toc entries (links), unhighlight all, then highlight viewed
    const list = document.getElementById("toc_list");
    if (!firstId || !list) return;
    const links = list.querySelectorAll("a");
    for (const link of links) link.dataset.viewing = "false";
    const link = list.querySelector('a[href="#' + firstId + '"]');
    if (!link) return;
    link.dataset.viewing = "true";
  }

  // get first or previous toc listed element in top half of view
  function getFirstInView(query) {
    // get all elements matching query and with id
    const elements = document.querySelectorAll(query);
    const elementsWithIds = [];
    for (const element of elements) {
      if (element.id) elementsWithIds.push(element);
    }

    // get first or previous element in top half of view
    for (let i = 0; i < elementsWithIds.length; i++) {
      const element = elementsWithIds[i];
      const prevElement = elementsWithIds[Math.max(0, i - 1)];
      if (element.getBoundingClientRect().top >= 0) {
        if (element.getBoundingClientRect().top < window.innerHeight / 2)
          return element.id;
        else return prevElement.id;
      }
    }
  }

  // make panel
  function makePanel() {
    // create panel
    const panel = document.createElement("div");
    panel.id = "toc_panel";
    if (bullets === "true") panel.dataset.bullets = "true";

    // create header
    const header = document.createElement("div");
    header.id = "toc_header";

    // create toc button
    const button = document.createElement("button");
    button.id = "toc_button";
    button.innerHTML = document.querySelector(".icon_th_list").innerHTML;
    button.title = "Table of Contents";
    button.classList.add("icon_button");

    // create header text
    const text = document.createElement("h4");
    text.innerHTML = "Table of Contents";

    // create container for toc list
    const list = document.createElement("div");
    list.id = "toc_list";

    // attach click listeners
    panel.addEventListener("click", onPanelClick);
    header.addEventListener("click", onHeaderClick);
    button.addEventListener("click", onButtonClick);

    // attach elements
    header.appendChild(button);
    header.appendChild(text);
    panel.appendChild(header);
    panel.appendChild(list);

    return panel;
  }

  // create toc entries (links) to each element of the specified types
  function makeEntries(panel) {
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) {
      // do not add link if element doesn't have assigned id
      if (!element.id) continue;

      // create link/list item
      const link = document.createElement("a");
      link.classList.add("toc_link");
      switch (element.tagName.toLowerCase()) {
        case "h1":
          link.dataset.level = "1";
          break;
        case "h2":
          link.dataset.level = "2";
          break;
        case "h3":
          link.dataset.level = "3";
          break;
        case "h4":
          link.dataset.level = "4";
          break;
      }
      link.title = element.innerText;
      let text = element.innerText;
      if (text.length > charLimit) text = text.slice(0, charLimit) + "...";
      link.innerHTML = text;
      link.href = "#" + element.id;
      link.addEventListener("click", onLinkClick);

      // attach link
      panel.querySelector("#toc_list").appendChild(link);
    }
  }

  // when panel is clicked
  function onPanelClick(event) {
    // stop click from propagating to window/document and closing panel
    event.stopPropagation();
  }

  // when header itself is clicked
  function onHeaderClick(event) {
    togglePanel();
  }

  // when button is clicked
  function onButtonClick(event) {
    togglePanel();
    // stop header underneath button from also being clicked
    event.stopPropagation();
  }

  // when link is clicked
  function onLinkClick(event) {
    if (clickClose === "true" || (clickClose === "auto" && isSmallScreen()))
      closePanel();
    else openPanel();
  }

  // open panel if closed, close if opened
  function togglePanel() {
    const panel = document.getElementById("toc_panel");
    if (!panel) return;

    if (panel.dataset.open === "true") closePanel();
    else openPanel();
  }

  // open panel
  function openPanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "true";
  }

  // close panel
  function closePanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "false";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- th list icon -->

<template class="icon_th_list">
  <!-- modified from: https://fontawesome.com/icons/th-list -->
  <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
    <path
      fill="currentColor"
      d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* toc panel */
    #toc_panel {
      box-sizing: border-box;
      position: fixed;
      top: 0;
      left: 0;
      background: #ffffff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      z-index: 2;
    }

    /* toc panel when closed */
    #toc_panel[data-open="false"] {
      min-width: 60px;
      width: 60px;
      height: 60px;
      border-right: solid 1px #bdbdbd;
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc panel when open */
    #toc_panel[data-open="true"] {
      min-width: 260px;
      max-width: 480px;
      /* keep panel edge consistent distance away from "page" edge */
      width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
      bottom: 0;
      border-right: solid 1px #bdbdbd;
    }

    /* toc panel header */
    #toc_header {
      box-sizing: border-box;
      display: flex;
      flex-direction: row;
      align-items: center;
      height: 60px;
      margin: 0;
      padding: 20px;
    }

    /* toc panel header when hovered */
    #toc_header:hover {
      cursor: pointer;
    }

    /* toc panel header when panel open */
    #toc_panel[data-open="true"] > #toc_header {
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc open/close header button */
    #toc_button {
      margin-right: 20px;
    }

    /* hide toc list and header text when closed */
    #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
    #toc_panel[data-open="false"] > #toc_list {
      display: none;
    }

    /* toc list of entries */
    #toc_list {
      box-sizing: border-box;
      width: 100%;
      padding: 20px;
      position: absolute;
      top: calc(60px + 1px);
      bottom: 0;
      overflow: auto;
    }

    /* toc entry, link to section in document */
    .toc_link {
      display: block;
      padding: 5px;
      position: relative;
      font-weight: 600;
      text-decoration: none;
    }

    /* toc entry when hovered or when "viewed" */
    .toc_link:hover,
    .toc_link[data-viewing="true"] {
      background: #f5f5f5;
    }

    /* toc entry, level 1 indentation */
    .toc_link[data-level="1"] {
      margin-left: 0;
    }

    /* toc entry, level 2 indentation */
    .toc_link[data-level="2"] {
      margin-left: 20px;
    }

    /* toc entry, level 3 indentation */
    .toc_link[data-level="3"] {
      margin-left: 40px;
    }

    /* toc entry, level 4 indentation */
    .toc_link[data-level="4"] {
      margin-left: 60px;
    }

    /* toc entry bullets */
    #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
      position: absolute;
      left: -15px;
      top: -1px;
      font-size: 1.5em;
    }

    /* toc entry, level 2 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
      content: "\2022";
    }

    /* toc entry, level 3 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
      content: "\25AB";
    }

    /* toc entry, level 4 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
      content: "-";
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* push <body> ("page") element down to make room for toc icon */
    .toc_body_nudge {
      padding-top: 60px;
    }

    /* toc icon when panel closed and not hovered */
    #toc_panel[data-open="false"]:not(:hover) {
      background: rgba(255, 255, 255, 0.75);
    }
  }

  /* always hide toc panel on print */
  @media only print {
    #toc_panel {
      display: none;
    }
  }
</style>
<!-- 
  Tooltips Plugin

  Makes it such that when the user hovers or focuses a link to a citation or
  figure, a tooltip appears with a preview of the reference content, along with
  arrows to navigate between instances of the same reference in the document.
-->

<script type="module">
  // whether user must click off to close tooltip instead of just un-hovering
  const clickClose = "false";
  // delay (in ms) between opening and closing tooltip
  const delay = "100";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach hover and focus listeners to link
      link.addEventListener("mouseover", onLinkHover);
      link.addEventListener("mouseleave", onLinkUnhover);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("touchend", onLinkTouch);
    }

    // attach mouse, key, and resize listeners to window
    window.addEventListener("mousedown", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("keyup", onKeyUp);
    window.addEventListener("resize", onResize);
  }

  // when link is hovered
  function onLinkHover() {
    // function to open tooltip
    const delayOpenTooltip = function () {
      openTooltip(this);
    }.bind(this);

    // run open function after delay
    this.openTooltipTimer = window.setTimeout(delayOpenTooltip, delay);
  }

  // when mouse leaves link
  function onLinkUnhover() {
    // cancel opening tooltip
    window.clearTimeout(this.openTooltipTimer);

    // don't close on unhover if option specifies
    if (clickClose === "true") return;

    // function to close tooltip
    const delayCloseTooltip = function () {
      // if tooltip open and if mouse isn't over tooltip, close
      const tooltip = document.getElementById("tooltip");
      if (tooltip && !tooltip.matches(":hover")) closeTooltip();
    };

    // run close function after delay
    this.closeTooltipTimer = window.setTimeout(delayCloseTooltip, delay);
  }

  // when link is focused (tabbed to)
  function onLinkFocus(event) {
    openTooltip(this);
  }

  // when link is touched on touch screen
  function onLinkTouch(event) {
    // attempt to force hover state on first tap always, and trigger
    // regular link click (and navigation) on second tap
    if (event.target === document.activeElement) event.target.click();
    else {
      document.activeElement.blur();
      event.target.focus();
    }
    if (event.cancelable) event.preventDefault();
    event.stopPropagation();
    return false;
  }

  // when mouse is clicked anywhere in window
  function onClick(event) {
    closeTooltip();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("tooltip_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("tooltip_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeTooltip();
        break;
    }
  }

  // when window is resized or zoomed
  function onResize() {
    closeTooltip();
  }

  // get all links of types we wish to handle
  function getLinks() {
    const queries = [];
    // exclude buttons, anchor links, toc links, etc
    const exclude =
      ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    queries.push('a[href^="#ref-"]' + exclude); // citation links
    queries.push('a[href^="#fig:"]' + exclude); // figure links
    const query = queries.join(", ");
    return document.querySelectorAll(query);
  }

  // get links with same target, get index of link in set, get total
  // same links
  function getSameLinks(link) {
    const sameLinks = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        sameLinks.push(otherLink);
    }

    return {
      elements: sameLinks,
      index: sameLinks.indexOf(link),
      total: sameLinks.length,
    };
  }

  // open tooltip
  function openTooltip(link) {
    // delete tooltip if it exists, start fresh
    closeTooltip();

    // make tooltip element
    const tooltip = makeTooltip(link);

    // if source couldn't be found and tooltip not made, exit
    if (!tooltip) return;

    // make navbar elements
    const navBar = makeNavBar(link);
    if (navBar) tooltip.firstElementChild.appendChild(navBar);

    // attach tooltip to page
    document.body.appendChild(tooltip);

    // position tooltip
    const position = function () {
      positionTooltip(link);
    };
    position();

    // if tooltip contains images, position again after they've loaded
    const imgs = tooltip.querySelectorAll("img");
    for (const img of imgs) img.addEventListener("load", position);
  }

  // close (delete) tooltip
  function closeTooltip() {
    const tooltip = document.getElementById("tooltip");
    if (tooltip) tooltip.remove();
  }

  // make tooltip
  function makeTooltip(link) {
    // get target element that link points to
    const source = getSource(link);

    // if source can't be found, exit
    if (!source) return;

    // create new tooltip
    const tooltip = document.createElement("div");
    tooltip.id = "tooltip";
    const tooltipContent = document.createElement("div");
    tooltipContent.id = "tooltip_content";
    tooltip.appendChild(tooltipContent);

    // make copy of source node and put in tooltip
    const sourceCopy = makeCopy(source);
    tooltipContent.appendChild(sourceCopy);

    // attach mouse event listeners
    tooltip.addEventListener("click", onTooltipClick);
    tooltip.addEventListener("mousedown", onTooltipClick);
    tooltip.addEventListener("touchstart", onTooltipClick);
    tooltip.addEventListener("mouseleave", onTooltipUnhover);

    // (for interaction with lightbox plugin)
    // transfer click on tooltip copied img to original img
    const sourceImg = source.querySelector("img");
    const sourceCopyImg = sourceCopy.querySelector("img");
    if (sourceImg && sourceCopyImg) {
      const clickImg = function () {
        sourceImg.click();
        closeTooltip();
      };
      sourceCopyImg.addEventListener("click", clickImg);
    }

    return tooltip;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
      "class",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // when tooltip is clicked
  function onTooltipClick(event) {
    // when user clicks on tooltip, stop click from transferring
    // outside of tooltip (eg, click off to close tooltip, or eg click
    // off to unhighlight same refs)
    event.stopPropagation();
  }

  // when tooltip is unhovered
  function onTooltipUnhover(event) {
    if (clickClose === "true") return;

    // make sure new mouse/touch/focus no longer over tooltip or any
    // element within it
    const tooltip = document.getElementById("tooltip");
    if (!tooltip) return;
    if (this.contains(event.relatedTarget)) return;

    closeTooltip();
  }

  // make nav bar to go betwen prev/next instances of same reference
  function makeNavBar(link) {
    // find other links to the same source
    const sameLinks = getSameLinks(link);

    // don't show nav bar when singular reference
    if (sameLinks.total <= 1) return;

    // find prev/next links with same target
    const prevLink = getPrevLink(link, sameLinks);
    const nextLink = getNextLink(link, sameLinks);

    // create nav bar
    const navBar = document.createElement("div");
    navBar.id = "tooltip_nav_bar";
    const text = sameLinks.index + 1 + " of " + sameLinks.total;

    // create nav bar prev/next buttons
    const prevButton = document.createElement("button");
    const nextButton = document.createElement("button");
    prevButton.id = "tooltip_prev_button";
    nextButton.id = "tooltip_next_button";
    prevButton.title =
      "Jump to the previous occurence of this item in the document [←]";
    nextButton.title =
      "Jump to the next occurence of this item in the document [→]";
    prevButton.classList.add("icon_button");
    nextButton.classList.add("icon_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;
    nextButton.innerHTML =
      document.querySelector(".icon_caret_right").innerHTML;
    navBar.appendChild(prevButton);
    navBar.appendChild(document.createTextNode(text));
    navBar.appendChild(nextButton);

    // attach click listeners to buttons
    prevButton.addEventListener("click", function () {
      onPrevNextClick(link, prevLink);
    });
    nextButton.addEventListener("click", function () {
      onPrevNextClick(link, nextLink);
    });

    return navBar;
  }

  // get previous link with same target
  function getPrevLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if < 1
    let index;
    if (sameLinks.index - 1 >= 0) index = sameLinks.index - 1;
    else index = sameLinks.total - 1;
    return sameLinks.elements[index];
  }

  // get next link with same target
  function getNextLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if > total
    let index;
    if (sameLinks.index + 1 <= sameLinks.total - 1) index = sameLinks.index + 1;
    else index = 0;
    return sameLinks.elements[index];
  }

  // get element that is target of link or url hash
  function getSource(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector('[id="' + id + '"]');
    if (!target) return;

    // if ref or figure, modify target to get expected element
    if (id.indexOf("ref-") === 0) target = target.querySelector(":nth-child(2)");
    else if (id.indexOf("fig:") === 0) target = target.querySelector("figure");

    return target;
  }

  // when prev/next arrow button is clicked
  function onPrevNextClick(link, prevNextLink) {
    if (link && prevNextLink)
      goToElement(prevNextLink, window.innerHeight * 0.5);
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);
    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // determine position to place tooltip based on link position in
  // viewport and tooltip size
  function positionTooltip(link, left, top) {
    const tooltipElement = document.getElementById("tooltip");
    if (!tooltipElement) return;

    // get convenient vars for position/dimensions of
    // link/tooltip/page/view
    link = getRectInPage(link);
    const tooltip = getRectInPage(tooltipElement);
    const view = getRectInPage();

    // horizontal positioning
    if (left)
      // use explicit value
      left = left;
    else if (link.left + tooltip.width < view.right)
      // fit tooltip to right of link
      left = link.left;
    else if (link.right - tooltip.width > view.left)
      // fit tooltip to left of link
      left = link.right - tooltip.width;
    // center tooltip in view
    else left = (view.right - view.left) / 2 - tooltip.width / 2;

    // vertical positioning
    if (top)
      // use explicit value
      top = top;
    else if (link.top - tooltip.height > view.top)
      // fit tooltip above link
      top = link.top - tooltip.height;
    else if (link.bottom + tooltip.height < view.bottom)
      // fit tooltip below link
      top = link.bottom;
    else {
      // center tooltip in view
      top = view.top + view.height / 2 - tooltip.height / 2;
      // nudge off of link to left/right if possible
      if (link.right + tooltip.width < view.right) left = link.right;
      else if (link.left - tooltip.width > view.left)
        left = link.left - tooltip.width;
    }

    tooltipElement.style.left = left + "px";
    tooltipElement.style.top = top + "px";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* tooltip container */
    #tooltip {
      position: absolute;
      width: 50%;
      min-width: 240px;
      max-width: 75%;
      z-index: 1;
    }

    /* tooltip content */
    #tooltip_content {
      margin-bottom: 5px;
      padding: 20px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
      overflow-wrap: break-word;
    }

    /* tooltip copy of paragraphs and figures */
    #tooltip_content > p,
    #tooltip_content > figure {
      margin: 0;
      max-height: 320px;
      overflow-y: auto;
    }

    /* tooltip copy of <img> */
    #tooltip_content > figure > img,
    #tooltip_content > figure > svg {
      max-height: 260px;
    }

    /* navigation bar */
    #tooltip_nav_bar {
      margin-top: 10px;
      text-align: center;
    }

    /* navigation bar previous/next buton */
    #tooltip_nav_bar > .icon_button {
      position: relative;
      top: 3px;
    }

    /* navigation bar previous button */
    #tooltip_nav_bar > .icon_button:first-of-type {
      margin-right: 5px;
    }

    /* navigation bar next button */
    #tooltip_nav_bar > .icon_button:last-of-type {
      margin-left: 5px;
    }
  }

  /* always hide tooltip on print */
  @media only print {
    #tooltip {
      display: none;
    }
  }
</style>
<!--
  Analytics Plugin (third-party) 
  
  Copy and paste code from Google Analytics or similar service here.
-->
<!-- 
  Annotations Plugin

  Allows public annotation of the  manuscript. See https://web.hypothes.is/.
-->

<script type="module">
  // configuration
  window.hypothesisConfig = function () {
    return {
      branding: {
        accentColor: "#2196f3",
        appBackgroundColor: "#f8f8f8",
        ctaBackgroundColor: "#f8f8f8",
        ctaTextColor: "#000000",
        selectionFontFamily: "Open Sans, Helvetica, sans serif",
        annotationFontFamily: "Open Sans, Helvetica, sans serif",
      },
    };
  };

  // hypothesis client script
  const embed = "https://hypothes.is/embed.js";
  // hypothesis annotation count query url
  const query = "https://api.hypothes.is/api/search?limit=0&url=";

  // start script
  function start() {
    const button = makeButton();
    document.body.insertBefore(button, document.body.firstChild);
    insertCount(button);
  }

  // make button
  function makeButton() {
    // create button
    const button = document.createElement("button");
    button.id = "hypothesis_button";
    button.innerHTML = document.querySelector(".icon_hypothesis").innerHTML;
    button.title = "Hypothesis annotations";
    button.classList.add("icon_button");

    function onClick(event) {
      onButtonClick(event, button);
    }

    // attach click listeners
    button.addEventListener("click", onClick);

    return button;
  }

  // insert annotations count
  async function insertCount(button) {
    // get annotation count from Hypothesis based on url
    let count = "-";
    try {
      const canonical = document.querySelector('link[rel="canonical"]');
      const location = window.location;
      const url = encodeURIComponent((canonical || location).href);
      const response = await fetch(query + url);
      const json = await response.json();
      count = json.total || "-";
    } catch (error) {
      console.log(error);
    }

    // put count into button
    const counter = document.createElement("span");
    counter.id = "hypothesis_count";
    counter.innerHTML = count;
    button.title = "View " + count + " Hypothesis annotations";
    button.append(counter);
  }

  // when button is clicked
  function onButtonClick(event, button) {
    const script = document.createElement("script");
    script.src = embed;
    document.body.append(script);
    button.remove();
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
  <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
  <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
    <path
      fill="currentColor"
      d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  /* hypothesis activation button */
  #hypothesis_button {
    box-sizing: border-box;
    position: fixed;
    top: 0;
    right: 0;
    width: 60px;
    height: 60px;
    background: #ffffff;
    border-radius: 0;
    border-left: solid 1px #bdbdbd;
    border-bottom: solid 1px #bdbdbd;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
    z-index: 2;
  }

  /* hypothesis button svg */
  #hypothesis_button > svg {
    position: relative;
    top: -4px;
  }

  /* hypothesis annotation count */
  #hypothesis_count {
    position: absolute;
    left: 0;
    right: 0;
    bottom: 5px;
  }

  /* side panel */
  .annotator-frame {
    width: 280px !important;
  }

  /* match highlight color to rest of theme */
  .annotator-highlights-always-on .annotator-hl {
    background-color: #ffeb3b !important;
  }

  /* match focused color to rest of theme */
  .annotator-hl.annotator-hl-focused {
    background-color: #ff8a65 !important;
  }

  /* match bucket bar color to rest of theme */
  .annotator-bucket-bar {
    background: #f5f5f5 !important;
  }

  /* always hide button, toolbar, and tooltip on print */
  @media only print {
    #hypothesis_button {
      display: none;
    }

    .annotator-frame {
      display: none !important;
    }

    hypothesis-adder {
      display: none !important;
    }
  }
</style>
<!-- 
  Mathjax Plugin (third-party) 

  Allows the proper rendering of math/equations written in LaTeX.
  See https://www.mathjax.org/.
-->

<script type="text/x-mathjax-config">
  // configuration
  MathJax.Hub.Config({
    "CommonHTML": { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    "SVG": { linebreaks: { automatic: true } },
    "fast-preview": { disabled: true }
  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
  crossorigin="anonymous"
></script>

<style>
  /* mathjax containers */
  .math.display > span:not(.MathJax_Preview) {
    /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
    display: flex !important;
    overflow-x: auto !important;
    overflow-y: hidden !important;
    justify-content: center;
    align-items: center;
    margin: 0 !important;
  }

  /* right click menu */
  .MathJax_Menu {
    border-radius: 5px !important;
    border: solid 1px #bdbdbd !important;
    box-shadow: none !important;
  }

  /* equation auto-number */
  span[id^="eq:"] > span.math.display + span {
    font-weight: 600;
  }

  /* equation */
  span[id^="eq:"] > span.math.display > span {
    /* nudge to make room for equation auto-number and anchor */
    margin-right: 60px !important;
  }
</style>
</body>
</html>
