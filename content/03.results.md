## Results



Fig 1- Pipeline of Segmentation: a) tomograms b) patchify the tomograms into 3d patches c) Segmentation Network d) probability masks  e) stitching patches back f) thresholding g) adaptive localized thresholding h) outlier removal i) radial profile




![UNET.](images/unet.png){#fig:unet width="10cm"}
Fig 2- U-Net - Input Size is 32^3, in each resolution we have two convolution layer followed by batch normalization layer and relu activation function. Intermediate sizes are written on top of arrows, number of convolution filters is written bottom of boxes. Skip connections shows concatenation of the features from contracting path (left side of the network) and expansive path (right side of the network).



Fig 3- a) a section from z axis of a tomogram’s presynaptic terminal of a neuron
b) predicted probability mask by the segmentation network
c) instance mask of the vesicles after post processing



Fig 4- Dice improvements after post processing of initial predicted mask (different colors correspond to different tomograms ): a) training datasets b) synaptosome test datasets c) Neuron test datasets 


Fig 5- Vesicle radius and position through radial profile and cross-correlation
Radial Profile Refinement A) couple of vesicles are not centered B) Radial Profile. Blue range is from membrane center to outer white halo center, this is the search range for the optimal radius. (smoothed by gaussian filtering) C) second derivative of radial profile
E, F, H, G) Same as above columns after refinement. (@Benoit change column naming)


Fig 6- Splitting adjacent vesicles. (@Benoit, how we should present it?)


Table 1- Evaluation of the segmentation- MDICE: Mask Dice coefficient for the predicted mask PDICE: Dice coefficient after post-processing SIGMA-d: diameter error on correctly detected vesicle, DELTA-c: average error center (nm) #Vesicles: number of expected vesicles TP: True Positive  FN: False Negative FP: False Positive


### Comparison of manual segmentation with automatic deep-learning based segmentation
Evaluation metric DICE for pixel/pixel analysis
Global analysis

![Dice coefficient and loss value for training and validation set.](images/blinddice.png){#fig:dice width="10cm"}


3d unet good for 3D processing
recent Nature methods paper by Ben Engel, DeepFinder -> Relion for STA creates mask to find more using dl
	-what are they doing, maybe compare that in the text, different aims; we might compare results we achieve (keep as bonus, revision)

3 different types of dl: classification, localization and segmentation
We specialize in accuratly segmenting 3D svs -> results
through the network, output is a mask, smooth DICE/ binary DICE = which one for our mask? one function for both? -> Amin will check
when we encounter error until now we remove sv(?), bug inside function -> fix bug for better performance, how many fail and why?
evaluation: objectwise evaluation for I/O, radius, center (according to nature paper) -> compare with manual seg
	other common evaluation tool other than DICE (Amin wants to check)
  
  
