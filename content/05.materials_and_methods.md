## Materials and methods

### Cryo-electron Tomography Datasets

Two datasets of different origin were used as input and test subjects for the automatic segmentation pipeline, respectively.
They consisted in rat synaptosomes primary neuron cultures derived from mice.
The preparation procedure of the samples from which the datasets were obtained as well as the biological analysis of these datasets was previously reported  [@doi:10.1101/2022.03.07.483217].

### Manual segmentation and automatic interboundary segment detection

Manual segmentation of SVs, mitochondria, the active zone PM, and of the segmentation region was done in IMOD (???Figure S4A&B???) [@10.1006/jsbi.1996.0013]. SVs were segmented as spheres.
The segmentation region marked the region to be analyzed by Pyto [@doi:10.1016/j.jsb.2016.10.004].
The analysis by Pyto was essentially the same as described previously [@doi:10.1083/jcb.200908082; @doi:10.1016/j.jsb.2016.10.004].
In short, the segmented region is divided in 1 voxel thick layers parallel to the active zone for distance calculations.
A hierarchical connectivity segmentation detects densities interconnecting boundaries.
The boundaries were synaptic vesicles and the active zone PM. Detected intervesicular segments are termed connectors and segments connecting vesicles to the active zone PM are called tethers (Figure `\_add figure number*`{.green}).
Distance calculations respective to SVs were done from SV center.
The segmentation procedure is conservative and tends to miss some tethers and connectors because of noise.
Consequently, the numbers of tethers and connectors should not be considered as absolute values, but rather to compare experimental groups.
As it was done before, an upper limit was set between 2100 and 3200 nm^3^ on segment volume.
The tomograms that were used for this analysis were binned by a factor of 2 to 3, resulting in voxel sizes between 2.1 and 2.4 nm.

### Pre-processing of manual segmentation outputs from IMOD for further use (jupyter notebook pre-pyto)
`probably not necessary to mention`


### Network architecture and training 



The used datasets included a total of 30 tomograms with heterogeneous pixel sizes, defocus and resolution.

1. All 9 tomograms Dataset: partially segmented and used for training (Synaptosome)
2. A single tomogram with the exactly same setup and sample preparation like the train dataset
3. 8 Synaptosome tomograms Dataset:  with ground truth (with an exceeding treatment on the samples)
4. 12 Neuron fully segmented tomograms Dataset: with completely different sample preparation and microscope setup

`\_this is not good place to talk about evalution *`{.green}


##### Create an Input Voxel Patch

The training set was prepared by splitting the 3D tomographic volume into 32x32x32 `\_voxels??*`{.green} sub volumes and keeping only volumes occupied by a sufficient amount (> 1000 voxels) of binarized vesicle labels.
The obtained sub volumes were randomly divided into ten subsets of the training set, this method is termed k-fold cross-validation in the field of machine learning. 
`\_this is a wrong statment we dont do cross validation just split(fold) data *`{.green}
All of these subsets or "folds" were used as training sets, as an entirely separate set of tomographic subvolumes was used for validation, to avoid overfitting.

`\_are the folds overlapping? are the tomograms normalized any further than the NAD from previous segmentation before feeding it to the deeplearning model? add image from odt??, the 2D slices of the subset are supposed to be 32x32x32, but seem to have a different size... padding?? ---> results*`{.green}

##### 3D U-Net architecture

The previously prepared subsets are fed into the 3D U-Net in batches of 50. `\_cite Ronneberger, what was changed compared to the original U-Net, is there a better publication to cite?*`{.green}
These were passed through the U-Net in a total of 200 epochs.
Batch normalization was applied before Rectified Linear Unit (ReLU) activation `\_was it? cite Ioffe & Szegedy, maybe? [@doi:10.48550/arXiv.1502.03167]*`{.green}.

`\_we do not use deconv layers, instead we upsample (by repeating the data) and then apply a convolution.*`{.green}
`\_as far as I know, nobody uses analysis/expantion path, encoder/decoder is the common and correct term.*`{.green}
The 3D U-Net architecture is composed of a contracting or analysis path!! (convolutional layers), and an expanding or synthesis path (deconvolutional!! layers) (Figure {@fig:unet}).
`\_did we wrote our own U-Net or do we need to quote someones github for the original framework*`{.green}
`\_we used CSBDeep for Convoultion blocks Benoit mentioned it in the introdction we can bring it here but github licence is BSD 3-Clause License whihc it means we dont need to reference *`{.green} 

![**Segmentation Network: U-Net.** Input Size is 32^3 `\_voxels??*`, in each resolution we have two convolution layers followed by batch normalization layer and rectified Linear Units (ReLU) activation function. Intermediate sizes are written on top of arrows, number of convolution filters is written bottom of boxes. Skip connections show concatenation of the features from contracting path (left side of the network) and expansive path (right side of the network).`\_explain different colors, do they correspond with the different steps? for example: red- max pooling 2x2x2? add figure legend?*`{.green} ](images/unet.png){#fig:unet width="10cm"}

`\_what do we use as initial encoder weights and backbone*`{.green} 
`\_code checked: keras- The Glorot uniform initializer, also called Xavier uniform initializer.*`{.green} 
During each layer of the analysis path, the convolution filter consisting of a 3x3x3 kernel, with randomly initialized weights, was moved over all the voxels in each subset twice `\_what do you mean by "twice"?  *`{.green}, each time taking their dot product.
This kernel extracts and enhances the features in different parts of the image.
This is followed by a ReLU function, which can be described as 

$$f(x)=max(0,x)$$

which will output the positive input directly, while setting the negative input to 0.

Between each layer, the voxels were condensed, or down sampled, via a max-pooling step of 2x2x2, in which the maximum value of the 2x2x2 voxel cube is put forth.
With every layer of the U-Net, the input size thereby halves, while the number of channels doubles.

While the analysis path focuses on the identification of the areas of interest, the synthesis part focuses on their localization.
The synthesis path of the U-Net uses the same basic architecture as the analysis path, with a slight variation of using up convolution operation and implementing skip connections, where feature maps of the analysis part are concatenated to the output of the transposed convolutions of the same level. 

`\_code checked:final = Conv3D(n_channel_out, (1,) * n_dim, activation='sigmoid')(unet) *`{.green} 
The sigmoid/Softmax `\_in the image you write Sigmoid but in the text Softmax, which activation function was used?*`{.green} activation function is the last block of the U-Net (Figure {@fig:unet}), it triggers the loss function, which converts the output from the decoder path into a mask, where each voxel is assigned as either vesicle or not-vesicle.
As the segmentation of vesicles can be considered a binary classification task, binary cross-entropy was implemented as a loss function.

$$Loss= -\frac{1}{output  size}\sum_{i=1}^{output size} y_i * log  ŷ_i + (1-y_1) * log  (1-ŷ_1)$$

with the *output size* being the number of scalar values in the model output, *ŷ_1_* being the *i*-th scalar value in the model output and *y_i_* being the corresponding target value.
`\_publication to cite?*`{.green}

To optimize the weights and reduce the loss function during training, the Adam optimizer was used [@doi:10.48550/arXiv.1412.6980].
200 epochs were run until the loss function reached a global minimum.
`\_it's a local minima, we are optimizing a non-convex function with thousands of parameters*`{.green}


##### Mask prediction

The tomograms are large, 3D volumes.
They therefore were split into 32x32x32 patches with a step size of 24 (stride) before the U-Net. 
The small prediction patches, which were the output of the U-Net, were then stitched together to get the final probability mask.

#### Transfer Learning / Neuron Dataset


### Postprocessing


#### Estimating Global Threshold

In electron microscopic images, dense areas of the specimen appear darker, as fewer electrons are able to pass through that area of the sample.
Therefore, the cellular and vesicular membrane, among other features, appear darker than the background.
Binary cross-entropy was utilized to binarize the obtained probability mask. 
To determine the required threshold, several threshold values (between 0.8 and 1.0) were tested and the one that minimized the average of luminance of all marginal voxels was selected.(srounnd of vesicles)
`\_add image from odt??*`{.green}

#### Adaptive Localized Threshold

The global threshold identifies the majority synaptic vesicles.
Some vesicles, however, are more difficult to detect.
This might be, due to high intensity variations within the tomogram, or because the predicted binarized labels are do not match the spherical shape of vesicles. `\_should go to results?*`{.green}

In terms of binarized lables not matching the spherical shape of vesicles, two main classes were identified: vesicles that were in close proximity to another and got connected, and vesicles, which were only partially captured. 
These two classes were then separated from the rightfully identified vesicles by comparing their label sizes and their extent value  (Ratio of pixels in the region to pixels in the total bounding box computed as area / (rows * cols)). `\_write this into a clean formula*`{.green}
In the next step, probability masks of the partially detected vesicles were expanded in an effort to find the correct mask.
The probability masks of the connected vesicles, however, were minimized by searching for a more precise threshold, with the goal of separating the vesicles.


#### Radial Profile

`\_@Benoit?*`{.green}

#### Outlier Removal

The feature space of predicted vesicle labels was defined, containing thickness, membrane density, and estimated radius of a vesicle. `\_@Benoit: after radial profile, we can add the definition of thinness and membrane as well*`{.blue}
To detect outliers in this multivariate space, Mahalanobis Distance (MD) was applied to calculate L2 norm distance on normalized variables using the covariance matrix of observation.
As an additional way to detect outliers, the p-value of MD was calculated, bringing this evaluation setup in iterative form.
If the MD p-value of a specific vesicle was not in a specific margin range (0-10), their radial profile was recalculated, and the label entirely removed if they again failed to pass the margin of the p-value.

#### Radius Estimation (Cross Correlation through Radial Profile)

`\_@Benoit?*`{.green}

### Analysis of Results

The evaluation framework was designed to assess the capabilities of the proposed toolbox for automatic synaptic vesicle segmentation.
The framework was not only designed to evaluate quantitatively performance of the neural network, but rather assay the segmentation of vesicles in practice `\_unsure what the last part means*`{.green}. `\_I tried to say we develop the software rather than an algorithm paper with ablation study kinda more trasnfer learning but however for tranfer learning we might need add finetunning the network or say this sentence in other way*`{.green}.
The pipeline also generates a specific output format, which is necessary to further analyze the presynaptic tomograms via another pre-developed toolbox (Pyto), which segments small molecular filaments associated to the synaptic vesicles, titled tethers and connectors.

#### DICE

The `\_general form??*`{.green} DICE coefficient for probabilistic subvolume maps was calculated after each epoch as a performance quantification while `\_during?*`{.green} training.
The probabilistic mask subvolumes were stitched back together, creating a probabilistic map of the whole tomogram. 
The Soft-DICE for the whole tomogram was calculated to evaluate the similarity of the predicted probability mask with ground truth. 
Note that soft-dice is equivalent to dice, when the input is binarized (which we will do at the end of the post-processing).


$$1-\frac{2\sum_{pixels} y_{true} y_{pred}%}{\sum_{pixels} y_{true}^2+\sum_{pixels} y_{pred}^2}$$

`\_shouln't it be voxels instead of pixels??*`{.green}
`\_yes voxel is right*`{.green}

THE DICE was also employed to monitor all stages of post-processing on the eventual label file, to observe the effect of each post-processing step.

#### Diameter Error

The diameter of a vesicle is one of its relevant characterizations, and it is predefined (see Outlier Removal). 
`\_which diameters are we using in this evaluation as input, pre- or post-outlier removal?*`{.green}
`\_after! I meant from that perentesis that radius or dimater we assume as one charectiristic of vesicle we might can write it better *`{.green}
The error of diameter estimation of true-detected vesicle is defined as 1 minus the proportion of diameters 

$$\delta d=1-\frac{min(dSi,dGTi)}{max(dSi,dGTi)}$$ {#eq:regular-equation}

where dGTi is the diameter of each true manual segmented vesicle, and dSi is the diameter of its estimation.

#### Center error

The center error is an euclidean distance of ground truth and corresponds to true predicted vesicles `\_true pos or true neg*`{.green}.
A vesicle was defined as a true-detected vesicle if the predicted center was located inside the hand-segmented vesicle and the other way around the center of prediction was located inside the predicted vesicle. 
`\_isn't this a bit too general, shouldn't this be a tighter evaluation?*`{.green}
`\_we assume this as hard condition to be true postive we could define like some % liek 50% intersection but this condition is generally harder`{.green}
This means the volume of intersection of the estimated vesicle with the distance of d to a ground truth vesicle with radius R is: 

$$V=\frac{1}{12}\pi(4R+d)(2R-d)$$

### Manuscript preparation
The manuscript was written with the open and collaborative scientific writing package Manubot [@doi:10.1371/journal.pcbi.1007128]. 
The source code and data for this manuscript are available at <https://github.com/aseedb/synaptic_tomo_ms>.
